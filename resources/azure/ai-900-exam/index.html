
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../../assets/dl-logo-big-512x512-color.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.0.5">
    
    
      
        <title>Microsoft Azure AI Fundamentals Certification (AI-900) Exam Questions - DrLiptons</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.a617204b.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.9204c3b2.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  <link rel="stylesheet" href="../../../overrides/assets/stylesheets/main.d9227bb8.min.css">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="indigo" data-md-color-accent="">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#microsoft-azure-ai-fundamentals-certification-ai-900-exam-questions" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="DrLiptons" class="md-header__button md-logo" aria-label="DrLiptons" data-md-component="logo">
      
  <img src="../../../assets/dl-logo-big-512x512-color.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            DrLiptons
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Microsoft Azure AI Fundamentals Certification (AI-900) Exam Questions
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="" data-md-color-primary="indigo" data-md-color-accent=""  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 1 7 7c0 2.38-1.19 4.47-3 5.74V17a1 1 0 0 1-1 1H9a1 1 0 0 1-1-1v-2.26C6.19 13.47 5 11.38 5 9a7 7 0 0 1 7-7M9 21v-1h6v1a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1m3-17a5 5 0 0 0-5 5c0 2.05 1.23 3.81 3 4.58V16h4v-2.42c1.77-.77 3-2.53 3-4.58a5 5 0 0 0-5-5z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent=""  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 0-7 7c0 2.38 1.19 4.47 3 5.74V17a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1v-2.26c1.81-1.27 3-3.36 3-5.74a7 7 0 0 0-7-7M9 21a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1H9v1z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../about/" class="md-tabs__link">
      About
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../wip/" class="md-tabs__link">
      In Progress
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../reference/" class="md-tabs__link">
        Reference
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../resource/" class="md-tabs__link">
        Resource
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="DrLiptons" class="md-nav__button md-logo" aria-label="DrLiptons" data-md-component="logo">
      
  <img src="../../../assets/dl-logo-big-512x512-color.png" alt="logo">

    </a>
    DrLiptons
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../about/" class="md-nav__link">
        About
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../wip/" class="md-nav__link">
        In Progress
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4">
          Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" >
      
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4_2">
          Python
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Python" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          Python
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/get-live-financial-data/" class="md-nav__link">
        Get Live Financial Data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/flight-deals/" class="md-nav__link">
        Flight Deals
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/alien-invaders/" class="md-nav__link">
        Alien Invaders
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/auto-job-app/" class="md-nav__link">
        Automated Job Application
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/price-tracker/" class="md-nav__link">
        Price Tracker
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/password-manager/" class="md-nav__link">
        Password Manager
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/text-2-morse-code/" class="md-nav__link">
        Text2MorseCode
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/stock-news-alerts/" class="md-nav__link">
        Stock News Alert
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/tetris/" class="md-nav__link">
        Tetris Clone
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3" type="checkbox" id="__nav_4_3" >
      
      
      
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4_3">
          TensorFlow
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="TensorFlow" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          TensorFlow
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1" type="checkbox" id="__nav_4_3_1" >
      
      
      
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4_3_1">
          Plant Disease Detection
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Plant Disease Detection" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_1">
          <span class="md-nav__icon md-icon"></span>
          Plant Disease Detection
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/pdd/plant-disease-detection/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/pdd/part-1-create-ml-model/" class="md-nav__link">
        Part 1 - Create ML Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/pdd/part-2-create-app/" class="md-nav__link">
        Part 2 - Desktop App
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/pdd/part-3-make-exe/" class="md-nav__link">
        Part 3 - Make Executable
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../references/object-detection/" class="md-nav__link">
        Object Detection
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5">
          Resource
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Resource" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Resource
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../resource/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_2" type="checkbox" id="__nav_5_2" >
      
      
      
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_2">
          Python
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Python" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          Python
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/scikit-learn/" class="md-nav__link">
        Scikit-Learn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/matplotlib/" class="md-nav__link">
        Matplotlib
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/numpy/" class="md-nav__link">
        Numpy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/pandas/" class="md-nav__link">
        Pandas
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../python/mplfinance/" class="md-nav__link">
        mplfinance
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3" type="checkbox" id="__nav_5_3" >
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3">
          TensorFlow
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="TensorFlow" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_3">
          <span class="md-nav__icon md-icon"></span>
          TensorFlow
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3_1" type="checkbox" id="__nav_5_3_1" >
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3_1">
          TensorFlow Exam
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="TensorFlow Exam" data-md-level="3">
        <label class="md-nav__title" for="__nav_5_3_1">
          <span class="md-nav__icon md-icon"></span>
          TensorFlow Exam
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/tf-exam/tf-exam-overview/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3_1_2" type="checkbox" id="__nav_5_3_1_2" >
      
      
      
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3_1_2">
          Coursera - DeepLearning.AI TensorFlow Developer
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Coursera - DeepLearning.AI TensorFlow Developer" data-md-level="4">
        <label class="md-nav__title" for="__nav_5_3_1_2">
          <span class="md-nav__icon md-icon"></span>
          Coursera - DeepLearning.AI TensorFlow Developer
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/tf-exam/cs-part-1/" class="md-nav__link">
        Part 1 - Introduction to TF
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/tf-exam/cs-part-2/" class="md-nav__link">
        Part 2 - CNN in TF
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/tf-exam/cs-part-3/" class="md-nav__link">
        Part 3 -  NLP in TF
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/tf-exam/cs-part-4/" class="md-nav__link">
        Part 4 - Time Series
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/tf-exam/pass-tensorflow-cert/" class="md-nav__link">
        How I past TensorFlow Exam
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/tf-model-bp/" class="md-nav__link">
        TensorFlow Blueprint
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3_3" type="checkbox" id="__nav_5_3_3" >
      
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3_3">
          TensorFlow Models
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="TensorFlow Models" data-md-level="3">
        <label class="md-nav__title" for="__nav_5_3_3">
          <span class="md-nav__icon md-icon"></span>
          TensorFlow Models
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/model-list/" class="md-nav__link">
        List of Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3_3_2" type="checkbox" id="__nav_5_3_3_2" >
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3_3_2">
          Neural Network Regressions
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Neural Network Regressions" data-md-level="4">
        <label class="md-nav__title" for="__nav_5_3_3_2">
          <span class="md-nav__icon md-icon"></span>
          Neural Network Regressions
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/simple-regression/" class="md-nav__link">
        NNR - House Prices
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/regression-boston-housing/" class="md-nav__link">
        NNR - Boston Housing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/titanic/" class="md-nav__link">
        NNR - Titanic
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3_3_3" type="checkbox" id="__nav_5_3_3_3" >
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3_3_3">
          Image Classification
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Image Classification" data-md-level="4">
        <label class="md-nav__title" for="__nav_5_3_3_3">
          <span class="md-nav__icon md-icon"></span>
          Image Classification
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/basic-fmnist/" class="md-nav__link">
        Basic Image Classification - FMNIST
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/image-classification-dogs-cats/" class="md-nav__link">
        Image Classification - Dogs & Cats
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/cnn-fmnist/" class="md-nav__link">
        CNN - FMNIST
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3_3_4" type="checkbox" id="__nav_5_3_3_4" >
      
      
      
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3_3_4">
          Natural Language Processing
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Natural Language Processing" data-md-level="4">
        <label class="md-nav__title" for="__nav_5_3_3_4">
          <span class="md-nav__icon md-icon"></span>
          Natural Language Processing
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/imdb/" class="md-nav__link">
        NLP - Binary-Class IMDB
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/nlp-1-binary/" class="md-nav__link">
        NLP - Binary-Class Disaster Tweets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/nlp-2-multi/" class="md-nav__link">
        NLP - Multi-Class PedMed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/nlp-3-sentiment/" class="md-nav__link">
        NLP - Multi-Class Sentiment Analysis
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3_3_5" type="checkbox" id="__nav_5_3_3_5" >
      
      
      
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3_3_5">
          Time Series
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Time Series" data-md-level="4">
        <label class="md-nav__title" for="__nav_5_3_3_5">
          <span class="md-nav__icon md-icon"></span>
          Time Series
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/ts-bitcoin/" class="md-nav__link">
        Time Series - Bitcoin Price Forecast
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/ts-weather/" class="md-nav__link">
        Time Series - Weather Forecast
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3_3_6" type="checkbox" id="__nav_5_3_3_6" >
      
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3_3_6">
          Miscellaneous
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Miscellaneous" data-md-level="4">
        <label class="md-nav__title" for="__nav_5_3_3_6">
          <span class="md-nav__icon md-icon"></span>
          Miscellaneous
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorflow/models/utilities/" class="md-nav__link">
        Utility Functions
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#question-1" class="md-nav__link">
    Question 1
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-2" class="md-nav__link">
    Question 2
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-3" class="md-nav__link">
    Question 3
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-4" class="md-nav__link">
    Question 4
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-5" class="md-nav__link">
    Question 5
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-6" class="md-nav__link">
    Question 6
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-7" class="md-nav__link">
    Question 7
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-8" class="md-nav__link">
    Question 8
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-9" class="md-nav__link">
    Question 9
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-10" class="md-nav__link">
    Question 10
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-11" class="md-nav__link">
    Question 11
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-12" class="md-nav__link">
    Question 12
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-13" class="md-nav__link">
    Question 13
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-14" class="md-nav__link">
    Question 14
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-15" class="md-nav__link">
    Question 15
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-16" class="md-nav__link">
    Question 16
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-17" class="md-nav__link">
    Question 17
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-18" class="md-nav__link">
    Question 18
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-19" class="md-nav__link">
    Question 19
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-20" class="md-nav__link">
    Question 20
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-21" class="md-nav__link">
    Question 21
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-22" class="md-nav__link">
    Question 22
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-23" class="md-nav__link">
    Question 23
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-24" class="md-nav__link">
    Question 24
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-25" class="md-nav__link">
    Question 25
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-26" class="md-nav__link">
    Question 26
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-27" class="md-nav__link">
    Question 27
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-28" class="md-nav__link">
    Question 28
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-29" class="md-nav__link">
    Question 29
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-30" class="md-nav__link">
    Question 30
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-31" class="md-nav__link">
    Question 31
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-32" class="md-nav__link">
    Question 32
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-33" class="md-nav__link">
    Question 33
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-34" class="md-nav__link">
    Question 34
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-35" class="md-nav__link">
    Question 35
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-36" class="md-nav__link">
    Question 36
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-37" class="md-nav__link">
    Question 37
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-38" class="md-nav__link">
    Question 38
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-39" class="md-nav__link">
    Question 39
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-40" class="md-nav__link">
    Question 40
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-41" class="md-nav__link">
    Question 41
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-42" class="md-nav__link">
    Question 42
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-43" class="md-nav__link">
    Question 43
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-44-obsolete" class="md-nav__link">
    Question 44 (Obsolete)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-45" class="md-nav__link">
    Question 45
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-46" class="md-nav__link">
    Question 46
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-47" class="md-nav__link">
    Question 47
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-48" class="md-nav__link">
    Question 48
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-49" class="md-nav__link">
    Question 49
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-50" class="md-nav__link">
    Question 50
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-51" class="md-nav__link">
    Question 51
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-52" class="md-nav__link">
    Question 52
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-53" class="md-nav__link">
    Question 53
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-54" class="md-nav__link">
    Question 54
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-55" class="md-nav__link">
    Question 55
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-56" class="md-nav__link">
    Question 56
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-57" class="md-nav__link">
    Question 57
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-58" class="md-nav__link">
    Question 58
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-59" class="md-nav__link">
    Question 59
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-60" class="md-nav__link">
    Question 60
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-61" class="md-nav__link">
    Question 61
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-62" class="md-nav__link">
    Question 62
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-63" class="md-nav__link">
    Question 63
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-64" class="md-nav__link">
    Question 64
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-65" class="md-nav__link">
    Question 65
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-66" class="md-nav__link">
    Question 66
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-67" class="md-nav__link">
    Question 67
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-68" class="md-nav__link">
    Question 68
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-69" class="md-nav__link">
    Question 69
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-70" class="md-nav__link">
    Question 70
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-71" class="md-nav__link">
    Question 71
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-72" class="md-nav__link">
    Question 72
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-73" class="md-nav__link">
    Question 73
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-74" class="md-nav__link">
    Question 74
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-75" class="md-nav__link">
    Question 75
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-76" class="md-nav__link">
    Question 76
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-77" class="md-nav__link">
    Question 77
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-78" class="md-nav__link">
    Question 78
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-79" class="md-nav__link">
    Question 79
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-80" class="md-nav__link">
    Question 80
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-81" class="md-nav__link">
    Question 81
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-82" class="md-nav__link">
    Question 82
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-83" class="md-nav__link">
    Question 83
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-84" class="md-nav__link">
    Question 84
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-85" class="md-nav__link">
    Question 85
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-86" class="md-nav__link">
    Question 86
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-87" class="md-nav__link">
    Question 87
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-88" class="md-nav__link">
    Question 88
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-89" class="md-nav__link">
    Question 89
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-90" class="md-nav__link">
    Question 90
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-91" class="md-nav__link">
    Question 91
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-92" class="md-nav__link">
    Question 92
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-93" class="md-nav__link">
    Question 93
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-94" class="md-nav__link">
    Question 94
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-95" class="md-nav__link">
    Question 95
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-96" class="md-nav__link">
    Question 96
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-97" class="md-nav__link">
    Question 97
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-98" class="md-nav__link">
    Question 98
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-99" class="md-nav__link">
    Question 99
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-100" class="md-nav__link">
    Question 100
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-101" class="md-nav__link">
    Question 101
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-102" class="md-nav__link">
    Question 102
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-103" class="md-nav__link">
    Question 103
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-104" class="md-nav__link">
    Question 104
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-105" class="md-nav__link">
    Question 105
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-106" class="md-nav__link">
    Question 106
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-107" class="md-nav__link">
    Question 107
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-108" class="md-nav__link">
    Question 108
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-109" class="md-nav__link">
    Question 109
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-110" class="md-nav__link">
    Question 110
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-111" class="md-nav__link">
    Question 111
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-112" class="md-nav__link">
    Question 112
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-113" class="md-nav__link">
    Question 113
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-114" class="md-nav__link">
    Question 114
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-115" class="md-nav__link">
    Question 115
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-116" class="md-nav__link">
    Question 116
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-117" class="md-nav__link">
    Question 117
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-118" class="md-nav__link">
    Question 118
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-119" class="md-nav__link">
    Question 119
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-120" class="md-nav__link">
    Question 120
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-121" class="md-nav__link">
    Question 121
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-122" class="md-nav__link">
    Question 122
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-123" class="md-nav__link">
    Question 123
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-124" class="md-nav__link">
    Question 124
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-125" class="md-nav__link">
    Question 125
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-126" class="md-nav__link">
    Question 126
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-127" class="md-nav__link">
    Question 127
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-128" class="md-nav__link">
    Question 128
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-129" class="md-nav__link">
    Question 129
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-130" class="md-nav__link">
    Question 130
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-131" class="md-nav__link">
    Question 131
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-132" class="md-nav__link">
    Question 132
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-133" class="md-nav__link">
    Question 133
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-134" class="md-nav__link">
    Question 134
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-135" class="md-nav__link">
    Question 135
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-136" class="md-nav__link">
    Question 136
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-137" class="md-nav__link">
    Question 137
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-138" class="md-nav__link">
    Question 138
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-139" class="md-nav__link">
    Question 139
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-140" class="md-nav__link">
    Question 140
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-141" class="md-nav__link">
    Question 141
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-142" class="md-nav__link">
    Question 142
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-143" class="md-nav__link">
    Question 143
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                

<h1 id="microsoft-azure-ai-fundamentals-certification-ai-900-exam-questions">Microsoft Azure AI Fundamentals Certification (AI-900) Exam Questions</h1>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>The questions in this website is a collection of free available resources from several sources. The use of any parts for commercial use is strictly prohabit. For personnal use only.</p>
</div>
<h2 id="question-1"><strong>Question 1</strong></h2>
<p>A company employs a team of customer service agents to provide telephone and email support to customers.</p>
<p>The company develops a webchat bot to provide automated answers to common customer queries.</p>
<p>Which business benefit should the company expect as a result of creating the webchat bot solution?</p>
<p><strong>A.</strong> increased sales</p>
<p><strong>B.</strong> a reduced workload for the customer service agents</p>
<p><strong>C.</strong> improved product reliability</p>
<details class="- success">
<summary>Answer 1</summary>
<p><strong>Correct Answer:</strong> B </p>
</details>
<h2 id="question-2"><strong>Question 2</strong></h2>
<p>For a machine learning progress, how should you split data for training and evaluation?</p>
<p><strong>A.</strong> Use features for training and labels for evaluation.</p>
<p><strong>B.</strong> Randomly split the data into rows for training and rows for evaluation.</p>
<p><strong>C.</strong> Use labels for training and features for evaluation.</p>
<p><strong>D.</strong> Randomly split the data into columns for training and columns for evaluation.</p>
<details class="- success">
<summary>Answer 2</summary>
<p><strong>Correct Answer:</strong> B </p>
<p>The Split Data module is particularly useful when you need to separate data into training and testing sets. Use the Split Rows option if you want to divide the data into two parts. You can specify the percentage of data to put in each split, but by default, the data is divided 50-50. You can also randomize the selection of rows in each group, and use stratified sampling.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/split-data">https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/split-data</a></p>
</details>
<h2 id="question-3"><strong>Question 3</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>You are developing a model to predict events by using classification.</p>
<p>You have a confusion matrix for the model scored on test data as shown in the following exhibit.</p>
<p><img alt="3-1q" src="../ai-900-images/3-1q.png" /></p>
<p>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="3-2q" src="../ai-900-images/3-2q.png" /></p>
<details class="- success">
<summary>Answer 3</summary>
<p><img alt="3-1a" src="../ai-900-images/3-1a.png" /></p>
<p><strong>Box 1:</strong> 11 -</p>
<p><img alt="3-2a" src="../ai-900-images/3-2a.png" /></p>
<p>TP = True Positive.</p>
<p>The class labels in the training set can take on only two possible values, which we usually refer to as positive or negative. The positive and negative instances that a classifier predicts correctly are called true positives (TP) and true negatives (TN), respectively. Similarly, the incorrectly classified instances are called false positives (FP) and false negatives (FN).</p>
<p><strong>Box 2:</strong> 1,033 -</p>
<p>FN = False Negative -</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio/evaluate-model-performance">https://docs.microsoft.com/en-us/azure/machine-learning/studio/evaluate-model-performance</a></p>
</details>
<h2 id="question-4"><strong>Question 4</strong></h2>
<p>You build a machine learning model by using the automated machine learning user interface (UI).</p>
<p>You need to ensure that the model meets the Microsoft transparency principle for responsible AI.</p>
<p>What should you do?</p>
<p><strong>A.</strong> Set Validation type to Auto.</p>
<p><strong>B.</strong> Enable Explain best model.</p>
<p><strong>C.</strong> Set Primary metric to accuracy.</p>
<p><strong>D.</strong> Set Max concurrent iterations to 0.</p>
<details class="- success">
<summary>Answer 4</summary>
<p><strong>Correct Answer:</strong> B </p>
<p>Model Explain Ability.</p>
<p>Most businesses run on trust and being able to open the ML ג€black boxג€ helps build transparency and trust. In heavily regulated industries like healthcare and banking, it is critical to comply with regulations and best practices. One key aspect of this is understanding the relationship between input variables (features) and model output. Knowing both the magnitude and direction of the impact each feature (feature importance) has on the predicted value helps better understand and explain the model. With model explain ability, we enable you to understand feature importance as part of automated ML runs.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://azure.microsoft.com/en-us/blog/new-automated-machine-learning-capabilities-in-azure-machine-learning-service/">https://azure.microsoft.com/en-us/blog/new-automated-machine-learning-capabilities-in-azure-machine-learning-service/</a></p>
</details>
<h2 id="question-5"><strong>Question 5</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="5q" src="../ai-900-images/5q.png" /></p>
<details class="- success">
<summary>Answer 5</summary>
<p><img alt="5a" src="../ai-900-images/5a.png" /></p>
<p>Anomaly detection encompasses many important tasks in machine learning:</p>
<p>Identifying transactions that are potentially fraudulent.</p>
<p>Learning patterns that indicate that a network intrusion has occurred.</p>
<p>Finding abnormal clusters of patients.</p>
<p>Checking values entered into a system.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/anomaly-detection">https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/anomaly-detection</a></p>
</details>
<h2 id="question-6"><strong>Question 6</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="6q" src="../ai-900-images/6q.png" /></p>
<details class="- success">
<summary>Answer 6</summary>
<p><strong>Correct Answer:</strong> reliability and safety</p>
<p>Reliability and safety:</p>
<p>AI systems need to be reliable and safe in order to be trusted. It is important for a system to perform as it was originally designed and for it to respond safely to new situations. Its inherent resilience should resist intended or unintended manipulation. Rigorous testing and validation should be established for operating conditions to ensure that the system responds safely to edge cases, and A/B testing and champion/challenger methods should be integrated into the evaluation process.</p>
<p>An AI system's performance can degrade over time, so a robust monitoring and model tracking process needs to be established to reactively and proactively measure the model's performance and retrain it, as necessary, to modernize it.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai">https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai</a></p>
</details>
<h2 id="question-7"><strong>Question 7</strong></h2>
<p><strong>DRAG DROP -</strong></p>
<p>Match the types of AI workloads to the appropriate scenarios.</p>
<p>To answer, drag the appropriate workload type from the column on the left to its scenario on the right. Each workload type may be used once, more than once, or not at all.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Select and Place:</strong></p>
<p><img alt="7q" src="../ai-900-images/7q.png" /></p>
<details class="- example">
<summary>Answer 7</summary>
<p><img alt="7a" src="../ai-900-images/7a.png" /></p>
<p><strong>Box 3:</strong> Natural language processing</p>
<p>Natural language processing (NLP) is used for tasks such as sentiment analysis, topic detection, language detection, key phrase extraction, and document categorization.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-language-processing">https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-language-processing</a></p>
</details>
<h2 id="question-8"><strong>Question 8</strong></h2>
<p>You are designing an AI system that empowers everyone, including people who have hearing, visual, and other impairments.</p>
<p>This is an example of which Microsoft guiding principle for responsible AI?</p>
<p><strong>A.</strong> fairness</p>
<p><strong>B.</strong> inclusiveness</p>
<p><strong>C.</strong> reliability and safety</p>
<p><strong>D.</strong> accountability</p>
<details class="- success">
<summary>Answer 8</summary>
<p><strong>Correct Answer:</strong> B </p>
<p>Inclusiveness: At Microsoft, we firmly believe everyone should benefit from intelligent technology, meaning it must incorporate and address a broad range of human needs and experiences. For the 1 billion people with disabilities around the world, AI technologies can be a game-changer.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles">https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles</a></p>
</details>
<h2 id="question-9"><strong>Question 9</strong></h2>
<p><strong>DRAG DROP -</strong></p>
<p>Match the Microsoft guiding principles for responsible AI to the appropriate descriptions.</p>
<p>To answer, drag the appropriate principle from the column on the left to its description on the right. Each principle may be used once, more than once, or not at all.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Select and Place:</strong></p>
<p><img alt="9q" src="../ai-900-images/9q.png" /></p>
<details class="- success">
<summary>Answer 9</summary>
<p><img alt="9a" src="../ai-900-images/9a.png" /></p>
<p><strong>Box 1:</strong> Reliability and safety -</p>
<p>To build trust, it's critical that AI systems operate reliably, safely, and consistently under normal circumstances and in unexpected conditions. These systems should be able to operate as they were originally designed, respond safely to unanticipated conditions, and resist harmful manipulation.</p>
<p><strong>Box 2:</strong> Accountability -</p>
<p>The people who design and deploy AI systems must be accountable for how their systems operate. Organizations should draw upon industry standards to develop accountability norms. These norms can ensure that AI systems are not the final authority on any decision that impacts people's lives and that humans maintain meaningful control over otherwise highly autonomous AI systems.</p>
<p><strong>Box 3:</strong> Privacy and security -</p>
<p>As AI becomes more prevalent, protecting privacy and securing important personal and business information is becoming more critical and complex. With AI, privacy and data security issues require especially close attention because access to data is essential for AI systems to make accurate and informed predictions and decisions about people. AI systems must comply with privacy laws that require transparency about the collection, use, and storage of data and mandate that consumers have appropriate controls to choose how their data is used</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles">https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles</a></p>
</details>
<h2 id="question-10"><strong>Question 10</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="10q" src="../ai-900-images/10q.jpg" /></p>
<details class="- success">
<summary>Answer 10</summary>
<p><strong>Correct Answer:</strong> reliability and safety</p>
<p>Reliability and safety: To build trust, it's critical that AI systems operate reliably, safely, and consistently under normal circumstances and in unexpected conditions.</p>
<p>These systems should be able to operate as they were originally designed, respond safely to unanticipated conditions, and resist harmful manipulation.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles">https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles</a></p>
</details>
<h2 id="question-11"><strong>Question 11</strong></h2>
<p>You are building an AI system.</p>
<p>Which task should you include to ensure that the service meets the Microsoft transparency principle for responsible AI?</p>
<p><strong>A.</strong> Ensure that all visuals have an associated text that can be read by a screen reader.</p>
<p><strong>B.</strong> Enable autoscaling to ensure that a service scales based on demand.</p>
<p><strong>C.</strong> Provide documentation to help developers debug code.</p>
<p><strong>D.</strong> Ensure that a training dataset is representative of the population.</p>
<details class="- success">
<summary>Answer 11</summary>
<p><strong>Correct Answer:</strong> C </p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles">https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles</a></p>
</details>
<h2 id="question-12"><strong>Question 12</strong></h2>
<p><strong>DRAG DROP -</strong></p>
<p>Match the types of AI workloads to the appropriate scenarios.</p>
<p>To answer, drag the appropriate workload type from the column on the left to its scenario on the right. Each workload type may be used once, more than once, or not at all.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Select and Place:</strong></p>
<p><img alt="12q" src="../ai-900-images/12q.png" /></p>
<details class="- success">
<summary>Answer 12</summary>
<p><img alt="12a" src="../ai-900-images/12a.png" /></p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/learn/paths/get-started-with-artificial-intelligence-on-azure/">https://docs.microsoft.com/en-us/learn/paths/get-started-with-artificial-intelligence-on-azure/</a></p>
</details>
<h2 id="question-13"><strong>Question 13</strong></h2>
<p>Your company is exploring the use of voice recognition technologies in its smart home devices. The company wants to identify any barriers that might unintentionally leave out specific user groups.</p>
<p>This an example of which Microsoft guiding principle for responsible AI?</p>
<p><strong>A.</strong> accountability</p>
<p><strong>B.</strong> fairness</p>
<p><strong>C.</strong> inclusiveness</p>
<p><strong>D.</strong> privacy and security</p>
<details class="- success">
<summary>Answer 13</summary>
<p><strong>Correct Answer:</strong> C </p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles">https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles</a></p>
</details>
<h2 id="question-14"><strong>Question 14</strong></h2>
<p>What are three Microsoft guiding principles for responsible AI? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> knowledgeability</p>
<p><strong>B.</strong> decisiveness</p>
<p><strong>C.</strong> inclusiveness</p>
<p><strong>D.</strong> fairness</p>
<p><strong>E.</strong> opinionatedness</p>
<p><strong>F.</strong> reliability and safety</p>
<details class="- success">
<summary>Answer 14</summary>
<p><strong>Correct Answer:</strong> C, D, and F </p>
<p>Reference:</p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles">https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles</a></p>
</details>
<h2 id="question-15"><strong>Question 15</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="15q" src="../ai-900-images/15q.png" /></p>
<details class="- success">
<summary>Answer 15</summary>
<p><strong>Correct Answer:</strong> object detection</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-detection">https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-detection</a></p>
</details>
<h2 id="question-16"><strong>Question 16</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="16q" src="../ai-900-images/16q.png" /></p>
<details class="- success">
<summary>Answer 16</summary>
<p><strong>Correct Answer:</strong> Feature engineering</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/create-features">https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/create-features</a></p>
</details>
<h2 id="question-17"><strong>Question 17</strong></h2>
<p>You run a charity event that involves posting photos of people wearing sunglasses on Twitter.</p>
<p>You need to ensure that you only retweet photos that meet the following requirements:</p>
<ul>
<li>Include one or more faces.</li>
<li>Contain at least one person wearing sunglasses.</li>
</ul>
<p>What should you use to analyze the images?</p>
<p><strong>A.</strong> the Verify operation in the Face service</p>
<p><strong>B.</strong> the Detect operation in the Face service</p>
<p><strong>C.</strong> the Describe Image operation in the Computer Vision service</p>
<p><strong>D.</strong> the Analyze Image operation in the Computer Vision service</p>
<details class="- success">
<summary>Answer 17</summary>
<p><strong>Correct Answer:</strong> B </p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/face/overview">https://docs.microsoft.com/en-us/azure/cognitive-services/face/overview</a></p>
</details>
<h2 id="question-18"><strong>Question 18</strong></h2>
<p>When you design an AI system to assess whether loans should be approved, the factors used to make the decision should be explainable.</p>
<p>This is an example of which Microsoft guiding principle for responsible AI?</p>
<p><strong>A.</strong> transparency</p>
<p><strong>B.</strong> inclusiveness</p>
<p><strong>C.</strong> fairness</p>
<p><strong>D.</strong> privacy and security</p>
<details class="- success">
<summary>Answer 18</summary>
<p><strong>Correct Answer:</strong> A </p>
<p>Achieving transparency helps the team to understand the data and algorithms used to train the model, what transformation logic was applied to the data, the final model generated, and its associated assets. This information offers insights about how the model was created, which allows it to be reproduced in a transparent way.</p>
<p><strong>Incorrect Answers:</strong></p>
<p><strong>B:</strong> Inclusiveness mandates that AI should consider all human races and experiences, and inclusive design practices can help developers to understand and address potential barriers that could unintentionally exclude people. Where possible, speech-to-text, text-to-speech, and visual recognition technology should be used to empower people with hearing, visual, and other impairments.</p>
<p><strong>C:</strong> Fairness is a core ethical principle that all humans aim to understand and apply. This principle is even more important when AI systems are being developed.</p>
<p>Key checks and balances need to make sure that the system's decisions don't discriminate or run a gender, race, sexual orientation, or religion bias toward a group or individual.</p>
<p><strong>D:</strong> A data holder is obligated to protect the data in an AI system, and privacy and security are an integral part of this system. Personal needs to be secured, and it should be accessed in a way that doesn't compromise an individual's privacy.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/strategy/responsible-ai">https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/strategy/responsible-ai</a></p>
</details>
<h2 id="question-19"><strong>Question 19</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="19q" src="../ai-900-images/19q.jpg" /></p>
<details class="- success">
<summary>Answer 19</summary>
<p><img alt="19a" src="../ai-900-images/19a.jpg" /></p>
<p><strong>Box 1:</strong> Yes -</p>
<p>Achieving transparency helps the team to understand the data and algorithms used to train the model, what transformation logic was applied to the data, the final model generated, and its associated assets. This information offers insights about how the model was created, which allows it to be reproduced in a transparent way.</p>
<p><strong>Box 2:</strong> No -</p>
<p>A data holder is obligated to protect the data in an AI system, and privacy and security are an integral part of this system. Personal needs to be secured, and it should be accessed in a way that doesn't compromise an individual's privacy.</p>
<p><strong>Box 3:</strong> No -</p>
<p>Inclusiveness mandates that AI should consider all human races and experiences, and inclusive design practices can help developers to understand and address potential barriers that could unintentionally exclude people. Where possible, speech-to-text, text-to-speech, and visual recognition technology should be used to empower people with hearing, visual, and other impairments.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai">https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai</a></p>
</details>
<h2 id="question-20"><strong>Question 20</strong></h2>
<p><strong>DRAG DROP -</strong></p>
<p>Match the principles of responsible AI to appropriate requirements.</p>
<p>To answer, drag the appropriate principles from the column on the left to its requirement on the right. Each principle may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Select and Place:</strong></p>
<p><img alt="20q" src="../ai-900-images/20q.jpg" /></p>
<details class="- success">
<summary>Answer 20</summary>
<p><img alt="20a" src="../ai-900-images/20a.jpg" /></p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles">https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles</a></p>
</details>
<h2 id="question-21"><strong>Question 21</strong></h2>
<p><strong>DRAG DROP -</strong></p>
<p>You plan to deploy an Azure Machine Learning model as a service that will be used by client applications.</p>
<p>Which three processes should you perform in sequence before you deploy the model? To answer, move the appropriate processes from the list of processes to the answer area and arrange them in the correct order.</p>
<p><strong>Select and Place:</strong></p>
<p><img alt="21q" src="../ai-900-images/21q.png" /></p>
<details class="- success">
<summary>Answer 21</summary>
<p><img alt="21a" src="../ai-900-images/21a.png" /></p>
<p>Reference:</p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-ml-pipelines">https://docs.microsoft.com/en-us/azure/machine-learning/concept-ml-pipelines</a></p>
</details>
<h2 id="question-22"><strong>Question 22</strong></h2>
<p>You are building an AI-based app.</p>
<p>You need to ensure that the app uses the principles for responsible AI.</p>
<p>Which two principles should you follow? Each correct answer presents part of the solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> Implement an Agile software development methodology</p>
<p><strong>B.</strong> Implement a process of AI model validation as part of the software review process</p>
<p><strong>C.</strong> Establish a risk governance committee that includes members of the legal team, members of the risk management team, and a privacy officer</p>
<p><strong>D.</strong> Prevent the disclosure of the use of AI-based algorithms for automated decision making</p>
<details class="- success">
<summary>Answer 22</summary>
<p><strong>Correct Answer:</strong> B and C </p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/3-implications-responsible-ai-practical">https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/3-implications-responsible-ai-practical</a></p>
</details>
<h2 id="question-23"><strong>Question 23</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="23q" src="../ai-900-images/23q.png" /></p>
<details class="- success">
<summary>Answer 23</summary>
<p><strong>Correct Answer:</strong> fairness</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai">https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai</a></p>
</details>
<h2 id="question-24"><strong>Question 24</strong></h2>
<p><strong>DRAG DROP -</strong></p>
<p>Match the machine learning tasks to the appropriate scenarios.</p>
<p>To answer, drag the appropriate task from the column on the left to its scenario on the right. Each task may be used once, more than once, or not at all.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Select and Place:</strong></p>
<p><img alt="24q" src="../ai-900-images/24q.png" /></p>
<details class="- success">
<summary>Answer 24</summary>
<p><img alt="24a" src="../ai-900-images/24a.png" /></p>
<p><strong>Box 1:</strong> Model evaluation -</p>
<p>The Model evaluation module outputs a confusion matrix showing the number of true positives, false negatives, false positives, and true negatives, as well as ROC, Precision/Recall, and Lift curves.</p>
<p><strong>Box 2:</strong> Feature engineering -</p>
<p>Feature engineering is the process of using domain knowledge of the data to create features that help ML algorithms learn better. In Azure Machine Learning, scaling and normalization techniques are applied to facilitate feature engineering. Collectively, these techniques and feature engineering are referred to as featurization.</p>
<p><strong>Note:</strong> Often, features are created from raw data through a process of feature engineering. For example, a time stamp in itself might not be useful for modeling until the information is transformed into units of days, months, or categories that are relevant to the problem, such as holiday versus working day.</p>
<p><strong>Box 3:</strong> Feature selection -</p>
<p>In machine learning and statistics, feature selection is the process of selecting a subset of relevant, useful features to use in building an analytical model. Feature selection helps narrow the field of data to the most valuable inputs. Narrowing the field of data helps reduce noise and improve training performance.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio/evaluate-model-performance">https://docs.microsoft.com/en-us/azure/machine-learning/studio/evaluate-model-performance</a> </p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml">https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml</a></p>
</details>
<h2 id="question-25"><strong>Question 25</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="25q" src="../ai-900-images/25q.png" /></p>
<details class="- success">
<summary>Answer 25</summary>
<p><strong>Correct Answer:</strong> features</p>
<p><strong>Reference:</strong></p>
<p><a href="https://www.baeldung.com/cs/feature-vs-label">https://www.baeldung.com/cs/feature-vs-label</a></p>
<p><a href="https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/">https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/</a></p>
</details>
<h2 id="question-26"><strong>Question 26</strong></h2>
<p>You have the Predicted vs. True chart shown in the following exhibit.</p>
<p><img alt="26q" src="../ai-900-images/26q.jpg" /></p>
<p>Which type of model is the chart used to evaluate?</p>
<p><strong>A.</strong> classification</p>
<p><strong>B.</strong> regression</p>
<p><strong>C.</strong> clustering</p>
<details class="- success">
<summary>Answer 26</summary>
<p><strong>Correct Answer:</strong> B </p>
<p>What is a Predicted vs. True chart?</p>
<p>Predicted vs. True shows the relationship between a predicted value and its correlating true value for a regression problem. This graph can be used to measure performance of a model as the closer to the y=x line the predicted values are, the better the accuracy of a predictive model.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-m">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-m</a></p>
</details>
<h2 id="question-27"><strong>Question 27</strong></h2>
<p>Which type of machine learning should you use to predict the number of gift cards that will be sold next month?</p>
<p><strong>A.</strong> classification</p>
<p><strong>B.</strong> regression</p>
<p><strong>C.</strong> clustering</p>
<details class="- success">
<summary>Answer 27</summary>
<p><strong>Correct Answer:</strong> B</p>
<p>In the most basic sense, regression refers to prediction of a numeric target.</p>
<p>Linear regression attempts to establish a linear relationship between one or more independent variables and a numeric outcome, or dependent variable.</p>
<p>You use this module to define a linear regression method, and then train a model using a labeled dataset. The trained model can then be used to make predictions.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/linear-regression">https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/linear-regression</a></p>
</details>
<h2 id="question-28"><strong>Question 28</strong></h2>
<p>You have a dataset that contains information about taxi journeys that occurred during a given period.</p>
<p>You need to train a model to predict the fare of a taxi journey.</p>
<p>What should you use as a feature?</p>
<p><strong>A.</strong> the number of taxi journeys in the dataset</p>
<p><strong>B.</strong> the trip distance of individual taxi journeys</p>
<p><strong>C.</strong> the fare of individual taxi journeys</p>
<p><strong>D.</strong> the trip ID of individual taxi journeys</p>
<details class="- success">
<summary>Answer 28</summary>
<p><strong>Correct Answer:</strong> B </p>
<p>The label is the column you want to predict. The identified Features are the inputs you give the model to predict the Label.</p>
<p><strong>Example:</strong></p>
<p>The provided data set contains the following columns:</p>
<p><strong>vendor_id:</strong> The ID of the taxi vendor is a feature.</p>
<p><strong>rate_code:</strong> The rate type of the taxi trip is a feature.</p>
<p><strong>passenger_count:</strong> The number of passengers on the trip is a feature. trip_time_in_secs: The amount of time the trip took. You want to predict the fare of the trip before the trip is completed. At that moment, you don't know how long the trip would take. Thus, the trip time is not a feature and you'll exclude this column from the model. trip_distance: The distance of the trip is a feature. payment_type: The payment method (cash or credit card) is a feature. fare_amount: The total taxi fare paid is the label.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/predict-prices">https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/predict-prices</a></p>
</details>
<h2 id="question-29"><strong>Question 29</strong></h2>
<p>You need to predict the sea level in meters for the next 10 years.</p>
<p>Which type of machine learning should you use?</p>
<p><strong>A.</strong> classification</p>
<p><strong>B.</strong> regression</p>
<p><strong>C.</strong> clustering</p>
<details class="- success">
<summary>Answer 29</summary>
<p><strong>Correct Answer:</strong> B</p>
<p>In the most basic sense, regression refers to prediction of a numeric target.</p>
<p>Linear regression attempts to establish a linear relationship between one or more independent variables and a numeric outcome, or dependent variable.</p>
<p>You use this module to define a linear regression method, and then train a model using a labeled dataset. The trained model can then be used to make predictions.</p>
<p>Reference:</p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/linear-regression">https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/linear-regression</a></p>
</details>
<h2 id="question-30"><strong>Question 30</strong></h2>
<p>HOTSPOT:</p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p>Hot Area:</p>
<table>
<thead>
<tr>
<th align="left">Statements</th>
<th align="center">Yes No</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Automated machine learning is the process of automating the time-consuming, iterative tasks of machine learning model development.</td>
<td align="center">⚪️ ⚪️</td>
</tr>
<tr>
<td align="left">Automated machine learning can automatically infer the training data from the use case provided. A graphical interface enabling no-code development of machine learning solutions</td>
<td align="center">⚪️ ⚪️</td>
</tr>
<tr>
<td align="left">Automated machine learning works by running multiple training iterations that are scored and ranked by the metrics you specify.</td>
<td align="center">⚪️ ⚪️</td>
</tr>
<tr>
<td align="left">Automated machine learning enables you to specify a dataset and will automatically understand which label to predict.</td>
<td align="center">⚪️ ⚪️</td>
</tr>
</tbody>
</table>
<details class="- success">
<summary>Answer 30</summary>
<table>
<thead>
<tr>
<th align="left">Statements</th>
<th align="center">Yes No</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Automated machine learning is the process of automating the time-consuming, iterative tasks of machine learning model development.</td>
<td align="center">🟢 ⚪️</td>
</tr>
<tr>
<td align="left">Automated machine learning can automatically infer the training data from the use case provided. A graphical interface enabling no-code development of machine learning solutions</td>
<td align="center">⚪️ 🟢️</td>
</tr>
<tr>
<td align="left">Automated machine learning works by running multiple training iterations that are scored and ranked by the metrics you specify.</td>
<td align="center">🟢 ⚪️</td>
</tr>
<tr>
<td align="left">Automated machine learning enables you to specify a dataset and will automatically understand which label to predict.</td>
<td align="center">⚪️ 🟢️</td>
</tr>
</tbody>
</table>
<p><strong>Box 1: Yes -</strong></p>
<p>Automated machine learning, also referred to as automated ML or AutoML, is the process of automating the time consuming, iterative tasks of machine learning model development. It allows data scientists, analysts, and developers to build ML models with high scale, efficiency, and productivity all while sustaining model quality.</p>
<p><strong>Box 2: No -</strong></p>
<p><strong>Box 3: Yes -</strong></p>
<p>During training, Azure Machine Learning creates a number of pipelines in parallel that try different algorithms and parameters for you. The service iterates through
ML algorithms paired with feature selections, where each iteration produces a model with a training score. The higher the score, the better the model is considered to "fit" your data. It will stop once it hits the exit criteria defined in the experiment.</p>
<p><strong>Box 4: No -</strong></p>
<p>Apply automated ML when you want Azure Machine Learning to train and tune a model for you using the target metric you specify.
The label is the column you want to predict.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://azure.microsoft.com/en-us/services/machine-learning/automatedml/#features">https://azure.microsoft.com/en-us/services/machine-learning/automatedml/#features</a></p>
</details>
<h2 id="question-31"><strong>Question 31</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="q31" src="../ai-900-images/31.png" /></p>
<details class="- success">
<summary>Answer 1</summary>
<p>Correct Answer: classification</p>
<p>Two-class classification provides the answer to simple two-choice questions such as Yes/No or True/False.</p>
</details>
<h2 id="question-32"><strong>Question 32</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.
<strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<table>
<thead>
<tr>
<th align="left">Statements</th>
<th align="center">Yes No</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Labelling is the process of tagging training data with known values</td>
<td align="center">⚪️ ⚪️</td>
</tr>
<tr>
<td align="left">You should evaluate a model by using the same data used to train the model</td>
<td align="center">⚪️ ⚪️</td>
</tr>
<tr>
<td align="left">Accuracy is always the primary metric used to measure a model's performance</td>
<td align="center">⚪️ ⚪️</td>
</tr>
</tbody>
</table>
<details class="- success">
<summary>Answer 32</summary>
<table>
<thead>
<tr>
<th align="left">Statements</th>
<th align="center">Yes No</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Labelling is the process of tagging training data with known values</td>
<td align="center">🟢 ⚪️</td>
</tr>
<tr>
<td align="left">You should evaluate a model by using the same data used to train the model</td>
<td align="center">⚪️ 🟢️</td>
</tr>
<tr>
<td align="left">Accuracy is always the primary metric used to measure a model's performance</td>
<td align="center">⚪️ 🟢️</td>
</tr>
</tbody>
</table>
<p><strong>Box 1: Yes -</strong></p>
<p>In machine learning, if you have labeled data, that means your data is marked up, or annotated, to show the target, which is the answer you want your machine learning model to predict.
In general, data labeling can refer to tasks that include data tagging, annotation, classification, moderation, transcription, or processing.</p>
<p><strong>Box 2: No -</strong></p>
<p><strong>Box 3: No -</strong></p>
<p>Accuracy is simply the proportion of correctly classified instances. It is usually the first metric you look at when evaluating a classifier. However, when the test data is unbalanced (where most of the instances belong to one of the classes), or you are more interested in the performance on either one of the classes, accuracy doesn't really capture the effectiveness of a classifier.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://www.cloudfactory.com/data-labeling-guide">https://www.cloudfactory.com/data-labeling-guide</a>
<a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio/evaluate-model-performance">https://docs.microsoft.com/en-us/azure/machine-learning/studio/evaluate-model-performance</a></p>
</details>
<h2 id="question-33"><strong>Question 33</strong></h2>
<p>Which service should you use to extract text, key/value pairs, and table data automatically from scanned documents?</p>
<p>A. Form Recognizer</p>
<p>B. Text Analytics</p>
<p>C. Language Understanding</p>
<p>D. Custom Vision</p>
<details class="- success">
<summary>Answer 33</summary>
<p><strong>Correct Answer:</strong> A </p>
<p>Accelerate your business processes by automating information extraction. Form Recognizer applies advanced machine learning to accurately extract text, key/ value pairs, and tables from documents. With just a few samples, Form Recognizer tailors its understanding to your documents, both on-premises and in the cloud. Turn forms into usable data at a fraction of the time and cost, so you can focus more time acting on the information rather than compiling it.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://azure.microsoft.com/en-us/services/cognitive-services/form-recognizer/">https://azure.microsoft.com/en-us/services/cognitive-services/form-recognizer/</a></p>
</details>
<h2 id="question-34"><strong>Question 34</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="34q" src="../ai-900-images/34q.png" /></p>
<details class="- success">
<summary>Answer 34</summary>
<p><strong>Answer:</strong> Form Recognizer</p>
<p>Accelerate your business processes by automating information extraction. Form Recognizer applies advanced machine learning to accurately extract text, key/ value pairs, and tables from documents. With just a few samples, Form Recognizer tailors its understanding to your documents, both on-premises and in the cloud. Turn forms into usable data at a fraction of the time and cost, so you can focus more time acting on the information rather than compiling it.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://azure.microsoft.com/en-us/services/cognitive-services/form-recognizer/">https://azure.microsoft.com/en-us/services/cognitive-services/form-recognizer/</a></p>
</details>
<h2 id="question-35"><strong>Question 35</strong></h2>
<p>You use Azure Machine Learning designer to publish an inference pipeline.</p>
<p>Which two parameters should you use to consume the pipeline? Each correct answer presents part of the solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><strong>A.</strong> the model name</p>
<p><strong>B.</strong> the training endpoint</p>
<p><strong>C.</strong> the authentication key</p>
<p><strong>D.</strong> the REST endpoint</p>
<details class="- success">
<summary>Answer 35</summary>
<p><strong>Correct Answer:</strong> C and D </p>
<p>You can consume a published pipeline in the Published pipelines page. Select a published pipeline and find the REST endpoint of it.</p>
<p>To consume the pipeline, you need:</p>
<ul>
<li>
<p>The REST endpoint for your service</p>
</li>
<li>
<p>The Primary Key for your service</p>
</li>
</ul>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-in/learn/modules/create-regression-model-azure-machine-learning-designer/deploy-service">https://docs.microsoft.com/en-in/learn/modules/create-regression-model-azure-machine-learning-designer/deploy-service</a></p>
</details>
<h2 id="question-36"><strong>Question 36</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="34q" src="../ai-900-images/36q.png" /></p>
<details class="- success">
<summary>Answer 36</summary>
<p><strong>Correct Answer:</strong> Aure Kubernetes Service (AKS)</p>
<p>To perform real-time inferencing, you must deploy a pipeline as a real-time endpoint.</p>
<p>Real-time endpoints must be deployed to an Azure Kubernetes Service cluster.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer#deploy">https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer#deploy</a></p>
</details>
<h2 id="question-37"><strong>Question 37</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="37" src="../ai-900-images/37q.png" /></p>
<details class="- success">
<summary>Answer 37</summary>
<p><strong>Correct Answer:</strong> Regression</p>
<p>In the most basic sense, regression refers to prediction of a numeric target.</p>
<p>Linear regression attempts to establish a linear relationship between one or more independent variables and a numeric outcome, or dependent variable.</p>
<p>You use this module to define a linear regression method, and then train a model using a labeled dataset. The trained model can then be used to make predictions.</p>
<p><strong>Incorrect Answers:</strong></p>
<ul>
<li>
<p>Classification is a machine learning method that uses data to determine the category, type, or class of an item or row of data.</p>
</li>
<li>
<p>Clustering, in machine learning, is a method of grouping data points into similar clusters. It is also called segmentation.</p>
</li>
</ul>
<p>Over the years, many clustering algorithms have been developed. Almost all clustering algorithms use the features of individual items to find similar items. For example, you might apply clustering to find similar people by demographics. You might use clustering with text analysis to group sentences with similar topics or sentiment.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/algorithm-module-reference/linear-regression https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/machine-learning-initialize-model-clustering">https://docs.microsoft.com/en-us/azure/machine-learning/algorithm-module-reference/linear-regression https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/machine-learning-initialize-model-clustering</a></p>
</details>
<h2 id="question-38"><strong>Question 38</strong></h2>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="38q" src="../ai-900-images/38q.png" /></p>
<details class="- success">
<summary>Answer 38</summary>
<p><img alt="38a" src="../ai-900-images/38a.png" /></p>
<p><strong>Box 1: Yes -</strong></p>
<p>Azure Machine Learning designer lets you visually connect datasets and modules on an interactive canvas to create machine learning models.</p>
<p><strong>Box 2: Yes -</strong></p>
<p>With the designer you can connect the modules to create a pipeline draft.</p>
<p>As you edit a pipeline in the designer, your progress is saved as a pipeline draft.</p>
<p><strong>Box 3: No -</strong></p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer">https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer</a></p>
</details>
<h2 id="question-39"><strong>Question 39</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>You have the following dataset.</p>
<p><img alt="39-1q" src="../ai-900-images/39-1q.png" /></p>
<p>You plan to use the dataset to train a model that will predict the house price categories of houses.</p>
<p>What are Household Income and House Price Category? To answer, select the appropriate option in the answer area.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="39-2q" src="../ai-900-images/39-2q.png" /></p>
<details class="- success">
<summary>Answer 39</summary>
<p><strong>Correct Answers:</strong></p>
<ul>
<li>
<p>A feature</p>
</li>
<li>
<p>A label</p>
</li>
</ul>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio/interpret-model-results">https://docs.microsoft.com/en-us/azure/machine-learning/studio/interpret-model-results</a></p>
</details>
<h2 id="question-40"><strong>Question 40</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="40q" src="../ai-900-images/40q.png" /></p>
<details class="- success">
<summary>Answer 40</summary>
<p><strong>Correct Answer:</strong> adding and connecting modules on a visual canvas.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer">https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer</a></p>
</details>
<h2 id="question-41"><strong>Question 41</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="41q" src="../ai-900-images/41q.png" /></p>
<details class="- success">
<summary>Answer 41</summary>
<p><img alt="41a" src="../ai-900-images/41a.png" /></p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-designer-python https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-designer-python https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml</a></p>
</details>
<h2 id="question-42"><strong>Question 42</strong></h2>
<p>A medical research project uses a large anonymized dataset of brain scan images that are categorized into predefined brain haemorrhage types.</p>
<p>You need to use machine learning to support early detection of the different brain haemorrhage types in the images before the images are reviewed by a person.</p>
<p>This is an example of which type of machine learning?</p>
<p><strong>A.</strong> clustering</p>
<p><strong>B.</strong> regression</p>
<p><strong>C.</strong> classification</p>
<details class="- success">
<summary>Answer 42</summary>
<p><strong>Correct Answer:</strong> C</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/create-classification-model-azure-machine-learning-designer/introduction">https://docs.microsoft.com/en-us/learn/modules/create-classification-model-azure-machine-learning-designer/introduction</a></p>
</details>
<h2 id="question-43"><strong>Question 43</strong></h2>
<p>When training a model, why should you randomly split the rows into separate subsets?</p>
<p><strong>A.</strong> to train the model twice to attain better accuracy</p>
<p><strong>B.</strong> to train multiple models simultaneously to attain better performance</p>
<p><strong>C.</strong> to test the model by using data that was not used to train the model</p>
<details class="- success">
<summary>Answer 43</summary>
<p><strong>Correct Answer:</strong> C</p>
</details>
<h2 id="question-44-obsolete"><strong>Question 44</strong> (Obsolete)</h2>
<p>You are evaluating whether to use a basic workspace or an enterprise workspace in Azure Machine Learning.</p>
<p>What are two tasks that require an enterprise workspace? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> Use a graphical user interface (GUI) to run automated machine learning experiments.</p>
<p><strong>B.</strong> Create a compute instance to use as a workstation.</p>
<p><strong>C.</strong> Use a graphical user interface (GUI) to define and run machine learning experiments from Azure Machine Learning designer.</p>
<p><strong>D.</strong> Create a dataset from a comma-separated value (CSV) file.</p>
<details class="- success">
<summary>Answer 44</summary>
<p><strong>Correct Answer:</strong> A and C</p>
<p>Note: Enterprise workspaces are no longer available as of September 2020. The basic workspace now has all the functionality of the enterprise workspace.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://www.azure.cn/en-us/pricing/details/machine-learning/">https://www.azure.cn/en-us/pricing/details/machine-learning/</a></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace">https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace</a></p>
</details>
<h2 id="question-45"><strong>Question 45</strong></h2>
<p>You need to predict the income range of a given customer by using the following dataset.</p>
<p><img alt="45q" src="../ai-900-images/45q.png" /></p>
<p>Which two fields should you use as features? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> Education Level</p>
<p><strong>B.</strong> Last Name</p>
<p><strong>C.</strong> Age</p>
<p><strong>D.</strong> Income Range</p>
<p><strong>E.</strong> First Name</p>
<details class="- success">
<summary>Answer 45</summary>
<p><strong>Correct Answer:</strong> A and C </p>
<p>First Name, Last Name, Age and Education Level are features. Income range is a label (what you want to predict). First Name and Last Name are irrelevant in that they have no bearing on income. Age and Education level are the features you should use.</p>
</details>
<h2 id="question-46"><strong>Question 46</strong></h2>
<p>The solution will use a custom model.</p>
<p>Which Azure Cognitive Services service should you use?</p>
<p><strong>A.</strong> Custom Vision</p>
<p><strong>B.</strong> Form Recognizer</p>
<p><strong>C.</strong> Face</p>
<p><strong>D.</strong> Computer Vision</p>
<details class="- success">
<summary>Answer 46</summary>
<p><strong>Correct Answer:</strong> A </p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/overview">https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/overview</a></p>
</details>
<h2 id="question-47"><strong>Question 47</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="47q" src="../ai-900-images/47q.jpg" /></p>
<details class="- success">
<summary>Answer 47</summary>
<p><img alt="47a" src="../ai-900-images/47a.jpg" /></p>
<p>Clustering is a machine learning task that is used to group instances of data into clusters that contain similar characteristics. Clustering can also be used to identify relationships in a dataset</p>
<p>Regression is a machine learning task that is used to predict the value of the label from a set of related features.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks">https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks</a></p>
</details>
<h2 id="question-48"><strong>Question 48</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="48q" src="../ai-900-images/48q.jpg" /></p>
<details class="- success">
<summary>Answer 48</summary>
<p><img alt="48a" src="../ai-900-images/48a.jpg" /></p>
<p><strong>Box 1:</strong> No -</p>
<p>The validation dataset is different from the test dataset that is held back from the training of the model.</p>
<p><strong>Box 2:</strong> Yes -</p>
<p>A validation dataset is a sample of data that is used to give an estimate of model skill while tuning modelג€™s hyperparameters.</p>
<p><strong>Box 3:</strong> No -</p>
<p>The Test Dataset, not the validation set, used for this. The Test Dataset is a sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://machinelearningmastery.com/difference-test-validation-datasets/">https://machinelearningmastery.com/difference-test-validation-datasets/</a></p>
</details>
<h2 id="question-49"><strong>Question 49</strong></h2>
<p>What are two metrics that you can use to evaluate a regression model? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> coefficient of determination (R2)</p>
<p><strong>B.</strong> F1 score</p>
<p><strong>C.</strong> root mean squared error (RMSE)</p>
<p><strong>D.</strong> area under curve (AUC)</p>
<p><strong>E.</strong> balanced accuracy</p>
<details class="- success">
<summary>Answer 49</summary>
<p><strong>Correct Answer:</strong> A and C</p>
<p><strong>A:</strong> R-squared (R2), or Coefficient of determination represents the predictive power of the model as a value between -inf and 1.00. 1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</p>
<p><strong>C:</strong> RMS-loss or Root Mean Squared Error (RMSE) (also called Root Mean Square Deviation, RMSD), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</p>
<p><strong>Incorrect Answers:</strong></p>
<p><strong>B:</strong> F1 score also known as balanced F-score or F-measure is used to evaluate a classification model.</p>
<p><strong>D:</strong> aucROC or area under the curve (AUC) is used to evaluate a classification model.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/metrics">https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/metrics</a></p>
</details>
<h2 id="question-50"><strong>Question 50</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="50q" src="../ai-900-images/50q.jpg" /></p>
<details class="- success">
<summary>Answer 50</summary>
<p><strong>Correct Answer:</strong> regression</p>
<p>Regression is a machine learning task that is used to predict the value of the label from a set of related features.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks">https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks</a></p>
</details>
<h2 id="question-51"><strong>Question 51</strong></h2>
<p><strong>DRAG DROP -</strong></p>
<p>You need to use Azure Machine Learning designer to build a model that will predict automobile prices.</p>
<p>Which type of modules should you use to complete the model? To answer, drag the appropriate modules to the correct locations. Each module may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Select and Place:</strong></p>
<p><img alt="51q" src="../ai-900-images/51q.png" /></p>
<details class="- success">
<summary>Answer 51</summary>
<p><img alt="51-1a" src="../ai-900-images/51-1a.png" /></p>
<p><strong>Box 1:</strong> Select Columns in Dataset</p>
<p>For Columns to be cleaned, choose the columns that contain the missing values you want to change. You can choose multiple columns, but you must use the same replacement method in all selected columns.</p>
<p>Example:</p>
<p><img alt="51-2a" src="../ai-900-images/51-2a.jpg" /></p>
<p><strong>Box 2:</strong> Split data -</p>
<p>Splitting data is a common task in machine learning. You will split your data into two separate datasets. One dataset will train the model and the other will test how well the model performed.</p>
<p><strong>Box 3:</strong> Linear regression -</p>
<p>Because you want to predict price, which is a number, you can use a regression algorithm. For this example, you use a linear regression model.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-designer-automobile-price-train-score">https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-designer-automobile-price-train-score</a></p>
</details>
<h2 id="question-52"><strong>Question 52</strong></h2>
<p>Which type of machine learning should you use to identify groups of people who have similar purchasing habits?</p>
<p><strong>A.</strong> classification</p>
<p><strong>B.</strong> regression</p>
<p><strong>C.</strong> clustering</p>
<details class="- success">
<summary>Answer 52</summary>
<p><strong>Correct Answer:</strong> C</p>
<p>Clustering is a machine learning task that is used to group instances of data into clusters that contain similar characteristics. Clustering can also be used to identify relationships in a dataset</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks">https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks</a></p>
</details>
<h2 id="question-53"><strong>Question 53</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="53q" src="../ai-900-images/53q.jpg" /></p>
<details class="- success">
<summary>Answer 53</summary>
<p><strong>Correct Answer:</strong> Regression</p>
<p>Regression is a machine learning task that is used to predict the value of the label from a set of related features.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks">https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks</a></p>
</details>
<h2 id="question-54"><strong>Question 54</strong></h2>
<p>Which metric can you use to evaluate a classification model?</p>
<p><strong>A.</strong> true positive rate</p>
<p><strong>B.</strong> mean absolute error (MAE)</p>
<p><strong>C.</strong> coefficient of determination (R2)</p>
<p><strong>D.</strong> root mean squared error (RMSE)</p>
<details class="- success">
<summary>Answer 54</summary>
<p><strong>Correct Answer:</strong> A </p>
<p>What does a good model look like?</p>
<p>An ROC curve that approaches the top left corner with 100% true positive rate and 0% false positive rate will be the best model. A random model would display as a flat line from the bottom left to the top right corner. Worse than random would dip below the y=x line.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml#classification">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml#classification</a></p>
</details>
<h2 id="question-55"><strong>Question 55</strong></h2>
<p>Which two components can you drag onto a canvas in Azure Machine Learning designer? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> dataset</p>
<p><strong>B.</strong> compute</p>
<p><strong>C.</strong> pipeline</p>
<p><strong>D.</strong> module</p>
<details class="- success">
<summary>Answer 55</summary>
<p><strong>Correct Answer:</strong> A and D </p>
<p>You can drag-and-drop datasets and modules onto the canvas.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer">https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer</a></p>
</details>
<h2 id="question-56"><strong>Question 56</strong></h2>
<p>You need to create a training dataset and validation dataset from an existing dataset.</p>
<p>Which module in the Azure Machine Learning designer should you use?</p>
<p><strong>A.</strong> Select Columns in Dataset</p>
<p><strong>B.</strong> Add Rows</p>
<p><strong>C.</strong> Split Data</p>
<p><strong>D.</strong> Join Data</p>
<details class="- success">
<summary>Answer 56</summary>
<p><strong>Correct Answer:</strong> C </p>
<p>A common way of evaluating a model is to divide the data into a training and test set by using Split Data, and then validate the model on the training data.</p>
<p>Use the Split Data module to divide a dataset into two distinct sets.</p>
<p>The studio currently supports training/validation data splits</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-cross-validation-data-splits">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-cross-validation-data-splits</a></p>
</details>
<h2 id="question-57"><strong>Question 57</strong></h2>
<p><strong>DRAG DROP -</strong></p>
<p>Match the types of machine learning to the appropriate scenarios.</p>
<p>To answer, drag the appropriate machine learning type from the column on the left to its scenario on the right. Each machine learning type may be used once, more than once, or not at all.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Select and Place:</strong></p>
<p><img alt="57q" src="../ai-900-images/57q.jpg" /></p>
<details class="- success">
<summary>Answer 57</summary>
<p><img alt="57a" src="../ai-900-images/57a.jpg" /></p>
<p><strong>Box 1: Regression -</strong></p>
<p>In the most basic sense, regression refers to prediction of a numeric target.</p>
<p>Linear regression attempts to establish a linear relationship between one or more independent variables and a numeric outcome, or dependent variable.</p>
<p>You use this module to define a linear regression method, and then train a model using a labeled dataset. The trained model can then be used to make predictions.</p>
<p><strong>Box 2: Clustering -</strong></p>
<p>Clustering, in machine learning, is a method of grouping data points into similar clusters. It is also called segmentation.</p>
<p>Over the years, many clustering algorithms have been developed. Almost all clustering algorithms use the features of individual items to find similar items. For example, you might apply clustering to find similar people by demographics. You might use clustering with text analysis to group sentences with similar topics or sentiment.</p>
<p><strong>Box 3: Classification -</strong></p>
<p>Two-class classification provides the answer to simple two-choice questions such as Yes/No or True/False.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/linear-regression">https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/linear-regression</a></p>
</details>
<h2 id="question-58"><strong>Question 58</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="58q" src="../ai-900-images/58q.png" /></p>
<details class="- success">
<summary>Answer 58</summary>
<p><strong>Correct Answer:</strong> Accuracy</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier">https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier</a></p>
</details>
<h2 id="question-59"><strong>Question 59</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="59q" src="../ai-900-images/59q.png" /></p>
<details class="- success">
<summary>Answer 59</summary>
<p><strong>Correct Answer:</strong> a reliability and safety</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai">https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/trusted-ai</a></p>
</details>
<h2 id="question-60"><strong>Question 60</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="60q" src="../ai-900-images/60q.png" /></p>
<details class="- success">
<summary>Answer 60</summary>
<p><strong>Corrector Answer:</strong> feature selection.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/architecture/data-science-process/create-features">https://docs.microsoft.com/en-us/azure/architecture/data-science-process/create-features</a></p>
</details>
<h2 id="question-61"><strong>Question 61</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="61q" src="../ai-900-images/61q.png" /></p>
<details class="- success">
<summary>Answer 61</summary>
<p><strong>Correct Answer:</strong> labeling.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-label-data">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-label-data</a></p>
</details>
<h2 id="question-62"><strong>Question 62</strong></h2>
<p>Your company wants to build a recycling machine for bottles. The recycling machine must automatically identify bottles of the correct shape and reject all other items.</p>
<p>Which type of AI workload should the company use?</p>
<p><strong>A.</strong> anomaly detection</p>
<p><strong>B.</strong> conversational AI</p>
<p><strong>C.</strong> computer vision</p>
<p><strong>D.</strong> natural language processing</p>
<details class="- success">
<summary>Answer 62</summary>
<p><strong>Correct Answer:</strong> C </p>
<p>Azure's Computer Vision service gives you access to advanced algorithms that process images and return information based on the visual features you're interested in. For example, Computer Vision can determine whether an image contains adult content, find specific brands or objects, or find human faces.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview">https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview</a></p>
</details>
<h2 id="question-63"><strong>Question 63</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="63q" src="../ai-900-images/63q.png" /></p>
<details class="- success">
<summary>Answer 63</summary>
<p><img alt="63a" src="../ai-900-images/63a.png" /></p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/get-started-build-detector">https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/get-started-build-detector</a></p>
</details>
<h2 id="question-64"><strong>Question 64</strong></h2>
<p>In which two scenarios can you use the Form Recognizer service? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> Extract the invoice number from an invoice.</p>
<p><strong>B.</strong> Translate a form from French to English.</p>
<p><strong>C.</strong> Find image of product in a catalog.</p>
<p><strong>D.</strong> Identify the retailer from a receipt.</p>
<details class="- success">
<summary>Answer 64</summary>
<p><strong>Correct Answer:</strong> A and D </p>
<p><strong>Reference:</strong></p>
<p><a href="https://azure.microsoft.com/en-gb/services/cognitive-services/form-recognizer/#features">https://azure.microsoft.com/en-gb/services/cognitive-services/form-recognizer/#features</a></p>
</details>
<h2 id="question-65"><strong>Question 65</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>You have a database that contains a list of employees and their photos.</p>
<p>You are tagging new photos of the employees.</p>
<p>For each of the following statements select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="65a" src="../ai-900-images/65q.png" /></p>
<details class="- success">
<summary>Answer 65</summary>
<p><strong>Correct Answer:</strong> Yes / Yes / No</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/face/overview">https://docs.microsoft.com/en-us/azure/cognitive-services/face/overview</a> </p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/face/concepts/face-detection">https://docs.microsoft.com/en-us/azure/cognitive-services/face/concepts/face-detection</a></p>
</details>
<h2 id="question-66"><strong>Question 66</strong></h2>
<p>You need to develop a mobile app for employees to scan and store their expenses while travelling.</p>
<p>Which type of computer vision should you use?</p>
<p><strong>A.</strong> semantic segmentation</p>
<p><strong>B.</strong> image classification</p>
<p><strong>C.</strong> object detection</p>
<p><strong>D.</strong> optical character recognition (OCR)</p>
<details class="- success">
<summary>Answer 66</summary>
<p><strong>Correct Answer:</strong> D </p>
<p>Azure's Computer Vision API includes Optical Character Recognition (OCR) capabilities that extract printed or handwritten text from images. You can extract text from images, such as photos of license plates or containers with serial numbers, as well as from documents - invoices, bills, financial reports, articles, and more.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-recognizing-text">https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-recognizing-text</a></p>
</details>
<h2 id="question-67"><strong>Question 67</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="67q" src="../ai-900-images/67q.png" /></p>
<details class="- success">
<summary>Answer 67</summary>
<p><img alt="67a" src="../ai-900-images/67a.png" /></p>
<p><strong>Box 1: Yes -</strong></p>
<p>Custom Vision functionality can be divided into two features. Image classification applies one or more labels to an image. Object detection is similar, but it also returns the coordinates in the image where the applied label(s) can be found.</p>
<p><strong>Box 2: Yes -</strong></p>
<p>The Custom Vision service uses a machine learning algorithm to analyze images. You, the developer, submit groups of images that feature and lack the characteristics in question. You label the images yourself at the time of submission. Then, the algorithm trains to this data and calculates its own accuracy by testing itself on those same images.</p>
<p><strong>Box 3: No -</strong></p>
<p>Custom Vision service can be used only on graphic files.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/Custom-Vision-Service/overview">https://docs.microsoft.com/en-us/azure/cognitive-services/Custom-Vision-Service/overview</a></p>
</details>
<h2 id="question-68"><strong>Question 68</strong></h2>
<p>You are processing photos of runners in a race.</p>
<p>You need to read the numbers on the runners' shirts to identity the runners in the photos.</p>
<p>Which type of computer vision should you use?</p>
<p><strong>A.</strong> facial recognition</p>
<p><strong>B.</strong> optical character recognition (OCR)</p>
<p><strong>C.</strong> semantic segmentation</p>
<p><strong>D.</strong> object detection</p>
<details class="- success">
<summary>Answer 68</summary>
<p><strong>Correct Answer:</strong> B </p>
<p>Optical character recognition (OCR) allows you to extract printed or handwritten text from images and documents.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview-ocr">https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview-ocr</a></p>
</details>
<h2 id="question-69"><strong>Question 69</strong></h2>
<p><strong>DRAG DROP -</strong></p>
<p>Match the types of machine learning to the appropriate scenarios.</p>
<p>To answer, drag the appropriate machine learning type from the column on the left to its scenario on the right. Each machine learning type may be used once, more than once, or not at all.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Select and Place:</strong></p>
<p><img alt="69q" src="../ai-900-images/69q.png" /></p>
<details class="- success">
<summary>Answer 69</summary>
<p><img alt="69a" src="../ai-900-images/69a.png" /></p>
<p><strong>Box 1:</strong> Image classification -</p>
<p>Image classification is a supervised learning problem: define a set of target classes (objects to identify in images), and train a model to recognize them using labeled example photos.</p>
<p><strong>Box 2:</strong> Object detection -</p>
<p>Object detection is a computer vision problem. While closely related to image classification, object detection performs image classification at a more granular scale. Object detection both locates and categorizes entities within images.</p>
<p><strong>Box 3:</strong> Semantic Segmentation -</p>
<p>Semantic segmentation achieves fine-grained inference by making dense predictions inferring labels for every pixel, so that each pixel is labeled with the class of its enclosing object ore region.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://developers.google.com/machine-learning/practica/image-classification">https://developers.google.com/machine-learning/practica/image-classification</a> </p>
<p><a href="https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/object-detection-model-builder">https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/object-detection-model-builder</a> </p>
<p><a href="https://nanonets.com/blog/how-to-do-semantic-segmentation-using-deep-learning/">https://nanonets.com/blog/how-to-do-semantic-segmentation-using-deep-learning/</a></p>
</details>
<h2 id="question-70"><strong>Question 70</strong></h2>
<p>You use drones to identify where weeds grow between rows of crops to send an instruction for the removal of the weeds.</p>
<p>This is an example of which type of computer vision?</p>
<p><strong>A.</strong> object detection</p>
<p><strong>B.</strong> optical character recognition (OCR)</p>
<p><strong>C.</strong> scene segmentation</p>
<details class="- success">
<summary>Answer 70</summary>
<p><strong>Correct Answer:</strong> A </p>
<p>Object detection is similar to tagging, but the API returns the bounding box coordinates for each tag applied. For example, if an image contains a dog, cat and person, the Detect operation will list those objects together with their coordinates in the image.</p>
<p><strong>Incorrect Answers:</strong></p>
<p><strong>B:</strong> Optical character recognition (OCR) allows you to extract printed or handwritten text from images and documents.</p>
<p><strong>C:</strong> Scene segmentation determines when a scene changes in video based on visual cues. A scene depicts a single event and it's composed by a series of consecutive shots, which are semantically related.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/ai-builder/object-detection-overview">https://docs.microsoft.com/en-us/ai-builder/object-detection-overview</a> </p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview-ocr">https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview-ocr</a> </p>
<p><a href="https://docs.microsoft.com/en-us/azure/azure-video-analyzer/video-analyzer-for-media-docs/video-indexer-overview">https://docs.microsoft.com/en-us/azure/azure-video-analyzer/video-analyzer-for-media-docs/video-indexer-overview</a></p>
</details>
<h2 id="question-71"><strong>Question 71</strong></h2>
<p><strong>DRAG DROP -</strong></p>
<p>Match the facial recognition tasks to the appropriate questions.</p>
<p>To answer, drag the appropriate task from the column on the left to its question on the right. Each task may be used once, more than once, or not at all.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Select and Place:</strong></p>
<p><img alt="71q" src="../ai-900-images/71q.png" /></p>
<details class="- success">
<summary>Answer 71</summary>
<p><img alt="71a" src="../ai-900-images/71a.png" /></p>
<p><strong>Box 1:</strong> verification -</p>
<p>Face verification: Check the likelihood that two faces belong to the same person and receive a confidence score.</p>
<p><strong>Box 2:</strong> similarity -</p>
<p><strong>Box 3:</strong> Grouping -</p>
<p><strong>Box 4:</strong> identification -</p>
<p>Face detection: Detect one or more human faces along with attributes such as: age, emotion, pose, smile, and facial hair, including 27 landmarks for each face in the image.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://azure.microsoft.com/en-us/services/cognitive-services/face/#features">https://azure.microsoft.com/en-us/services/cognitive-services/face/#features</a></p>
</details>
<h2 id="question-72"><strong>Question 72</strong></h2>
<p><strong>DRAG DROP -</strong></p>
<p>Match the types of computer vision workloads to the appropriate scenarios.</p>
<p>To answer, drag the appropriate workload type from the column on the left to its scenario on the right. Each workload type may be used once, more than once, or not at all.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>Select and Place:</strong></p>
<p><img alt="72q" src="../ai-900-images/72q.jpg" /></p>
<details class="- success">
<summary>Answer 72</summary>
<p><img alt="72a" src="../ai-900-images/72a.jpg" /></p>
<p><strong>Box 1:</strong> Facial recognition -</p>
<p>Face detection that perceives faces and attributes in an image; person identification that matches an individual in your private repository of up to 1 million people; perceived emotion recognition that detects a range of facial expressions like happiness, contempt, neutrality, and fear; and recognition and grouping of similar faces in images.</p>
<p><strong>Box 2:</strong> OCR -</p>
<p><strong>Box 3:</strong> Objection detection -</p>
<p>Object detection is similar to tagging, but the API returns the bounding box coordinates (in pixels) for each object found. For example, if an image contains a dog, cat and person, the Detect operation will list those objects together with their coordinates in the image. You can use this functionality to process the relationships between the objects in an image. It also lets you determine whether there are multiple instances of the same tag in an image.</p>
<p>The Detect API applies tags based on the objects or living things identified in the image. There is currently no formal relationship between the tagging taxonomy and the object detection taxonomy. At a conceptual level, the Detect API only finds objects and living things, while the Tag API can also include contextual terms like "indoor", which can't be localized with bounding boxes.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://azure.microsoft.com/en-us/services/cognitive-services/face/ https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-detection">https://azure.microsoft.com/en-us/services/cognitive-services/face/ https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-detection</a></p>
</details>
<h2 id="question-73"><strong>Question 73</strong></h2>
<p>You need to determine the location of cars in an image so that you can estimate the distance between the cars.</p>
<p>Which type of computer vision should you use?</p>
<p><strong>A.</strong> optical character recognition (OCR)</p>
<p><strong>B.</strong> object detection</p>
<p><strong>C.</strong> image classification</p>
<p><strong>D.</strong> face detection</p>
<details class="- success">
<summary>Answer 73</summary>
<p><strong>Correct Answer:</strong> B </p>
<p>Object detection is similar to tagging, but the API returns the bounding box coordinates (in pixels) for each object found. For example, if an image contains a dog, cat and person, the Detect operation will list those objects together with their coordinates in the image. You can use this functionality to process the relationships between the objects in an image. It also lets you determine whether there are multiple instances of the same tag in an image.</p>
<p>The Detect API applies tags based on the objects or living things identified in the image. There is currently no formal relationship between the tagging taxonomy and the object detection taxonomy. At a conceptual level, the Detect API only finds objects and living things, while the Tag API can also include contextual terms like "indoor", which can't be localized with bounding boxes.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-detection">https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-detection</a></p>
</details>
<h2 id="question-74"><strong>Question 74</strong></h2>
<p><strong>HOTSPOT -</strong></p>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p><strong>Hot Area:</strong></p>
<p><img alt="74q" src="../ai-900-images/74q.png" /></p>
<details class="- success">
<summary>Answer 74</summary>
<p><strong>Correct Answer:</strong> Custom Vision</p>
<p>Azure Custom Vision is a cognitive service that lets you build, deploy, and improve your own image classifiers. An image classifier is an AI service that applies labels (which represent classes) to images, according to their visual characteristics. Unlike the Computer Vision service, Custom Vision allows you to specify the labels to apply.</p>
<p><strong>Note:</strong> The Custom Vision service uses a machine learning algorithm to apply labels to images. You, the developer, must submit groups of images that feature and lack the characteristics in question. You label the images yourself at the time of submission. Then the algorithm trains to this data and calculates its own accuracy by testing itself on those same images. Once the algorithm is trained, you can test, retrain, and eventually use it to classify new images according to the needs of your app. You can also export the model itself for offline use.</p>
<p><strong>Incorrect Answers:</strong></p>
<p><strong>Computer Vision:</strong></p>
<p>Azure's Computer Vision service provides developers with access to advanced algorithms that process images and return information based on the visual features you're interested in. For example, Computer Vision can determine whether an image contains adult content, find specific brands or objects, or find human faces.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/home">https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/home</a></p>
</details>
<h2 id="question-75"><strong>Question 75</strong></h2>
<p>You send an image to a Computer Vision API and receive back the annotated image shown in the exhibit.</p>
<p><img alt="75q" src="../ai-900-images/75q.jpg" /></p>
<p>Which type of computer vision was used?</p>
<p><strong>A.</strong> object detection</p>
<p><strong>B.</strong> semantic segmentation</p>
<p><strong>C.</strong> optical character recognition (OCR)</p>
<p><strong>D.</strong> image classification</p>
<details class="- success">
<summary>Answer 75</summary>
<p><strong>Correct Answer:</strong> A </p>
<p>Object detection is similar to tagging, but the API returns the bounding box coordinates (in pixels) for each object found. For example, if an image contains a dog, cat and person, the Detect operation will list those objects together with their coordinates in the image. You can use this functionality to process the relationships between the objects in an image. It also lets you determine whether there are multiple instances of the same tag in an image.</p>
<p>The Detect API applies tags based on the objects or living things identified in the image. There is currently no formal relationship between the tagging taxonomy and the object detection taxonomy. At a conceptual level, the Detect API only finds objects and living things, while the Tag API can also include contextual terms like "indoor", which can't be localized with bounding boxes.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-detection">https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-detection</a></p>
</details>
<h2 id="question-76"><strong>Question 76</strong></h2>
<p>What are two tasks that can be performed by using the Computer Vision service? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> Train a custom image classification model.</p>
<p><strong>B.</strong> Detect faces in an image.</p>
<p><strong>C.</strong> Recognize handwritten text.</p>
<p><strong>D.</strong> Translate the text in an image between languages.</p>
<details class="- success">
<summary>Answer 76</summary>
<p><strong>Correct Answer:</strong> B and C </p>
<p><strong>B:</strong> Azure's Computer Vision service provides developers with access to advanced algorithms that process images and return information based on the visual features you're interested in. For example, Computer Vision can determine whether an image contains adult content, find specific brands or objects, or find human faces.</p>
<p><strong>C:</strong> Computer Vision includes Optical Character Recognition (OCR) capabilities. You can use the new Read API to extract printed and handwritten text from images and documents.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/home">https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/home</a></p>
</details>
<h2 id="question-77"><strong>Question 77</strong></h2>
<p>What is a use case for classification?</p>
<p><strong>A.</strong> predicting how many cups of coffee a person will drink based on how many hours the person slept the previous night.</p>
<p><strong>B.</strong> analyzing the contents of images and grouping images that have similar colors</p>
<p><strong>C.</strong> predicting whether someone uses a bicycle to travel to work based on the distance from home to work</p>
<p><strong>D.</strong> predicting how many minutes it will take someone to run a race based on past race times</p>
<details class="- success">
<summary>Answer 77</summary>
<p><strong>Correct Answer:</strong> B</p>
<p>Classification is a machine learning method that uses data to determine the category, type, or class of an item or row of data.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/algorithm-module-reference/linear-regression">https://docs.microsoft.com/en-us/azure/machine-learning/algorithm-module-reference/linear-regression</a></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/machine-learning-initialize-model-clustering">https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/machine-learning-initialize-model-clustering</a></p>
</details>
<h2 id="question-78"><strong>Question 78</strong></h2>
<p>Your website has a chatbot to assist customers.</p>
<p>You need to detect when a customer is upset based on what the customer types in the chatbot.</p>
<p>Which type of AI workload should you use?</p>
<p><strong>A.</strong> anomaly detection</p>
<p><strong>B.</strong> semantic segmentation</p>
<p><strong>C.</strong> regression</p>
<p><strong>D.</strong> natural language processing</p>
<details class="- success">
<summary>Answer 78</summary>
<p><strong>Correct Answer:</strong> D</p>
<p>Natural language processing (NLP) is used for tasks such as sentiment analysis, topic detection, language detection, key phrase extraction, and document categorization.</p>
<p>Sentiment Analysis is the process of determining whether a piece of writing is positive, negative or neutral.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-language-processing">https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-language-processing</a></p>
</details>
<h2 id="question-79"><strong>Question 79</strong></h2>
<p>Which AI service can you use to interpret the meaning of a user input such as "Call me back later?"</p>
<p><strong>A.</strong> Translator Text</p>
<p><strong>B.</strong> Text Analytics</p>
<p><strong>C.</strong> Speech</p>
<p><strong>D.</strong> Language Understanding (LUIS)</p>
<details class="- success">
<summary>Answer 79</summary>
<p><strong>Correct Answer:</strong> B</p>
<p>Text Analytics is an AI service that uncovers insights such as sentiment, entities, and key phrases in unstructured text.</p>
<p><strong>Incorrect Answers:</strong></p>
<p><strong>D:</strong> Language Understanding (LUIS) is a cloud-based API service, not an AI service, that applies custom machine-learning intelligence to a user's conversational, natural language text to predict overall meaning, and pull out relevant, detailed information.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/">https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/</a> </p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/luis/what-is-luis">https://docs.microsoft.com/en-us/azure/cognitive-services/luis/what-is-luis</a></p>
</details>
<h2 id="question-80"><strong>Question 80</strong></h2>
<p>You are developing a chatbot solution in Azure.</p>
<p>Which service should you use to determine a user's intent?</p>
<p><strong>A.</strong> Translator Text</p>
<p><strong>B.</strong> QnA Maker</p>
<p><strong>C.</strong> Speech</p>
<p><strong>D.</strong> Language Understanding (LUIS)</p>
<details class="- success">
<summary>Answer 80</summary>
<p><strong>Correct Answer</strong> D</p>
<p>Language Understanding (LUIS) is a cloud-based API service that applies custom machine-learning intelligence to a user's conversational, natural language text to predict overall meaning, and pull out relevant, detailed information.</p>
<p>Design your LUIS model with categories of user intentions called intents. Each intent needs examples of user utterances. Each utterance can provide data that needs to be extracted with machine-learning entities.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/luis/what-is-luis">https://docs.microsoft.com/en-us/azure/cognitive-services/luis/what-is-luis</a></p>
</details>
<h2 id="question-81"><strong>Question 81</strong></h2>
<p>You need to make the press releases of your company available in a range of languages.</p>
<p>Which service should you use?</p>
<p><strong>A.</strong> Translator Text</p>
<p><strong>B.</strong> Text Analytics</p>
<p><strong>C.</strong> Speech</p>
<p><strong>D.</strong> Language Understanding (LUIS)</p>
<details class="- success">
<summary>Answer 81</summary>
<p><strong>Correct Answer:</strong> A</p>
<p>Translator is a cloud-based machine translation service you can use to translate text in near real-time through a simple REST API call. The service uses modern neural machine translation technology and offers statistical machine translation technology. Custom Translator is an extension of Translator, which allows you to build neural translation systems.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/translator/">https://docs.microsoft.com/en-us/azure/cognitive-services/translator/</a></p>
</details>
<h2 id="question-82"><strong>Question 82</strong></h2>
<p>You are developing a natural language processing solution in Azure. The solution will analyze customer reviews and determine how positive or negative each review is.</p>
<p>This is an example of which type of natural language processing workload?</p>
<p><strong>A.</strong> language detection</p>
<p><strong>B.</strong> sentiment analysis</p>
<p><strong>C.</strong> key phrase extraction</p>
<p><strong>D.</strong> entity recognition</p>
<details class="- success">
<summary>Answer 82</summary>
<p><strong>Correct Answer:</strong> B</p>
<p>Sentiment Analysis is the process of determining whether a piece of writing is positive, negative or neutral.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-language-processing">https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-language-processing</a></p>
</details>
<h2 id="question-83"><strong>Question 83</strong></h2>
<p>You use natural language processing to process text from a Microsoft news story.</p>
<p>You receive the output shown in the following exhibit.</p>
<p><img alt="83q" src="../ai-900-images/83q.png" /></p>
<p>Which type of natural languages processing was performed?</p>
<p><strong>A.</strong> entity recognition</p>
<p><strong>B.</strong> key phrase extraction</p>
<p><strong>C.</strong> sentiment analysis</p>
<p><strong>D.</strong> translation</p>
<details class="- success">
<summary>Answer 83</summary>
<p><strong>Correct Answer:</strong> B</p>
<p>Key phrase extraction/ Broad entity extraction: Identify important concepts in text, including key phrases and named entities such as people, places, and organizations.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics">https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics</a></p>
</details>
<h2 id="question-84"><strong>Question 84</strong></h2>
<p>You are developing a solution that uses the Text Analytics service.</p>
<p>You need to identify the main talking points in a collection of documents.</p>
<p>Which type of natural language processing should you use?</p>
<p><strong>A.</strong> entity recognition</p>
<p><strong>B.</strong> key phrase extraction</p>
<p><strong>C.</strong> sentiment analysis</p>
<p><strong>D.</strong> language detection</p>
<details class="- success">
<summary>Answer 84</summary>
<p><strong>Correct Answer:</strong> B</p>
<p>Broad entity extraction: Identify important concepts in text, including key Key phrase extraction/ Broad entity extraction:</p>
<p>Identify important concepts in text, including key phrases and named entities such as people, places, and organizations.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-language-processing">https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/natural-language-processing</a></p>
</details>
<h2 id="question-85"><strong>Question 85</strong></h2>
<p>In which two scenarios can you use speech recognition? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> an in-car system that reads text messages aloud</p>
<p><strong>B.</strong> providing closed captions for recorded or live videos</p>
<p><strong>C.</strong> creating an automated public address system for a train station</p>
<p><strong>D.</strong> creating a transcript of a telephone call or meeting</p>
<details class="- success">
<summary>Answer 85</summary>
<p><strong>Correct Answer:</strong> B and D</p>
<p><a href="https://azure.microsoft.com/en-gb/services/cognitive-services/speech-to-text/#features">https://azure.microsoft.com/en-gb/services/cognitive-services/speech-to-text/#features</a></p>
</details>
<h2 id="question-86"><strong>Question 86</strong></h2>
<p>You need to build an app that will read recipe instructions aloud to support users who have reduced vision.</p>
<p>Which version service should you use?</p>
<p><strong>A.</strong> Text Analytics</p>
<p><strong>B.</strong> Translator Text</p>
<p><strong>C.</strong> Speech</p>
<p><strong>D.</strong> Language Understanding (LUIS)</p>
<details class="- success">
<summary>Answer 86</summary>
<p><strong>Correct Answer:</strong> C</p>
<p><a href="https://azure.microsoft.com/en-us/services/cognitive-services/text-to-speech/#features">https://azure.microsoft.com/en-us/services/cognitive-services/text-to-speech/#features</a></p>
</details>
<h2 id="question-87"><strong>Question 87</strong></h2>
<p>Which two scenarios are examples of a conversational AI workload? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> a telephone answering service that has a pre-recorder message</p>
<p><strong>B.</strong> a chatbot that provides users with the ability to find answers on a website by themselves</p>
<p><strong>C.</strong> telephone voice menus to reduce the load on human resources</p>
<p><strong>D.</strong> a service that creates frequently asked questions (FAQ) documents by crawling public websites</p>
<details class="- success">
<summary>Answer 87</summary>
<p><strong>Correct Answer:</strong> B and C</p>
<p><strong>B:</strong> A bot is an automated software program designed to perform a particular task. Think of it as a robot without a body.</p>
<p><strong>C:</strong> Automated customer interaction is essential to a business of any size. In fact, 61% of consumers prefer to communicate via speech, and most of them prefer self-service. Because customer satisfaction is a priority for all businesses, self-service is a critical facet of any customer-facing communications strategy.</p>
<p><strong>Incorrect Answers:</strong></p>
<p><strong>D:</strong> Early bots were comparatively simple, handling repetitive and voluminous tasks with relatively straightforward algorithmic logic. An example would be web crawlers used by search engines to automatically explore and catalog web content.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/architecture/data-guide/big-data/ai-overview">https://docs.microsoft.com/en-us/azure/architecture/data-guide/big-data/ai-overview</a> </p>
<p><a href="https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/interactive-voice-response-bot">https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/articles/interactive-voice-response-bot</a></p>
</details>
<h2 id="question-88"><strong>Question 88</strong></h2>
<p>You need to provide content for a business chatbot that will help answer simple user queries.</p>
<p>What are three ways to create question and answer text by using QnA Maker? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> Generate the questions and answers from an existing webpage.</p>
<p><strong>B.</strong> Use automated machine learning to train a model based on a file that contains the questions.</p>
<p><strong>C.</strong> Manually enter the questions and answers.</p>
<p><strong>D.</strong> Connect the bot to the Cortana channel and ask questions by using Cortana.</p>
<p><strong>E.</strong> Import chit-chat content from a predefined data source.</p>
<details class="- success">
<summary>Answer 88</summary>
<p><strong>Correct Answer:</strong> A, C, and E</p>
<p>Automatic extraction</p>
<p>Extract question-answer pairs from semi-structured content, including FAQ pages, support websites, excel files,</p>
<p>SharePoint documents, product manuals and policies.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/concepts/content-types">https://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/concepts/content-types</a></p>
</details>
<h2 id="question-89"><strong>Question 89</strong></h2>
<p>You have a frequently asked questions (FAQ) PDF file.</p>
<p>You need to create a conversational support system based on the FAQ.</p>
<p>Which service should you use?</p>
<p><strong>A.</strong> QnA Maker</p>
<p><strong>B.</strong> Text Analytics</p>
<p><strong>C.</strong> Computer Vision</p>
<p><strong>D.</strong> Language Understanding (LUIS)</p>
<details class="- success">
<summary>Answer 89</summary>
<p><strong>Correct Answer:</strong> A</p>
</details>
<h2 id="question-90"><strong>Question 90</strong></h2>
<p>You need to reduce the load on telephone operators by implementing a chatbot to answer simple questions with predefined answers.</p>
<p>Which two AI service should you use to achieve the goal? Each correct answer presents part of the solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> Text Analytics</p>
<p><strong>B.</strong> QnA Maker</p>
<p><strong>C.</strong> Azure Bot Service</p>
<p><strong>D.</strong> Translator Text</p>
<details class="- success">
<summary>Answer 90</summary>
<p><strong>Correct Answer:</strong> B and C</p>
<p>Bots are a popular way to provide support through multiple communication channels. You can use the QnA Maker service and Azure Bot Service to create a bot that answers user questions.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/build-faq-chatbot-qna-maker-azure-bot-service/">https://docs.microsoft.com/en-us/learn/modules/build-faq-chatbot-qna-maker-azure-bot-service/</a></p>
</details>
<h2 id="question-91"><strong>Question 91</strong></h2>
<p>Which two scenarios are examples of a conversational AI workload? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> a smart device in the home that responds to questions such as "What will the weather be like today?"</p>
<p><strong>B.</strong> a website that uses a knowledge base to interactively respond to users' questions</p>
<p><strong>C.</strong> assembly line machinery that autonomously inserts headlamps into cars</p>
<p><strong>D.</strong> monitoring the temperature of machinery to turn on a fan when the temperature reaches a specific threshold</p>
<details class="- success">
<summary>Answer 91</summary>
<p><strong>Correct Answer:</strong> A and B</p>
</details>
<h2 id="question-92"><strong>Question 92</strong></h2>
<p>You have the process shown in the following exhibit.</p>
<p><img alt="92q.png" src="../ai-900-images/92q.png" /></p>
<p>Which type AI solution is shown in the diagram?</p>
<p><strong>A.</strong> a sentiment analysis solution</p>
<p><strong>B.</strong> a chatbot</p>
<p><strong>C.</strong> a machine learning model</p>
<p><strong>D.</strong> a computer vision application</p>
<details class="- success">
<summary>Answer 92</summary>
<p><strong>Correct Answer:</strong> B</p>
</details>
<h2 id="question-93"><strong>Question 93</strong></h2>
<p>You need to develop a web-based AI solution for a customer support system. Users must be able to interact with a web app that will guide them to the best resource or answer.</p>
<p>Which service should you use?</p>
<p><strong>A.</strong> Custom Vision</p>
<p><strong>B.</strong> QnA Maker</p>
<p><strong>C.</strong> Translator Text</p>
<p><strong>D.</strong> Face</p>
<details class="- success">
<summary>Answer 93</summary>
<p><strong>Correct Answer:</strong> B</p>
<p>QnA Maker is a cloud-based API service that lets you create a conversational question-and-answer layer over your existing data. Use it to build a knowledge base by extracting questions and answers from your semi-structured content, including FAQs, manuals, and documents. Answer users' questions with the best answers from the QnAs in your knowledge base--automatically. Your knowledge base gets smarter, too, as it continually learns from user behavior.</p>
<p><strong>Incorrect Answers:</strong></p>
<p><strong>A:</strong> Azure Custom Vision is a cognitive service that lets you build, deploy, and improve your own image classifiers. An image classifier is an AI service that applies labels (which represent classes) to images, according to their visual characteristics. Unlike the Computer Vision service, Custom Vision allows you to specify the labels to apply.</p>
<p><strong>D:</strong> Azure Cognitive Services Face Detection API: At a minimum, each detected face corresponds to a faceRectangle field in the response. This set of pixel coordinates for the left, top, width, and height mark the located face. Using these coordinates, you can get the location of the face and its size. In the API response, faces are listed in size order from largest to smallest.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://azure.microsoft.com/en-us/services/cognitive-services/qna-maker/">https://azure.microsoft.com/en-us/services/cognitive-services/qna-maker/</a></p>
</details>
<h2 id="question-94"><strong>Question 94</strong></h2>
<p>Which AI service should you use to create a bot from a frequently asked questions (FAQ) document?</p>
<p><strong>A.</strong> QnA Maker</p>
<p><strong>B.</strong> Language Understanding (LUIS)</p>
<p><strong>C.</strong> Text Analytics</p>
<p><strong>D.</strong> Speech</p>
<details class="- success">
<summary>Answer 94</summary>
<p><strong>Correct Answer:</strong> A</p>
</details>
<h2 id="question-95"><strong>Question 95</strong></h2>
<p>Which scenario is an example of a webchat bot?</p>
<p><strong>A.</strong> Determine whether reviews entered on a website for a concert are positive or negative, and then add a thumbs up or thumbs down emoji to the reviews.</p>
<p><strong>B.</strong> Translate into English questions entered by customers at a kiosk so that the appropriate person can call the customers back.</p>
<p><strong>C.</strong> Accept questions through email, and then route the email messages to the correct person based on the content of the message.</p>
<p><strong>D.</strong> From a website interface, answer common questions about scheduled events and ticket purchases for a music festival.</p>
<details class="- success">
<summary>Answer 95</summary>
<p><strong>Correct Answer:</strong> D</p>
</details>
<h2 id="question-96"><strong>Question 96</strong></h2>
<p>You own a service desk company and employs a team of customer service agents to provide telephone and email support to customers.</p>
<p>Now you are planning to develop a web chatbot to automatically answer common customer queries. What business benefit the does owner expect as a result of the web chatbot?</p>
<p><strong>A.</strong> Increase sales</p>
<p><strong>B.</strong> Reduced workload for the customer service agents</p>
<p><strong>C.</strong> Improve product reliability</p>
<details class="- success">
<summary>Answer 96</summary>
<p><strong>Correct Answer:</strong> B</p>
</details>
<h2 id="question-97"><strong>Question 97</strong></h2>
<p><strong><em>_</em></strong><strong><em>_</em></strong>__ is the average of absolute differences between prediction and actual observation where all individual differences have equal weight.</p>
<p>Select the appropriate regression performance metrics from below to complete the sentence.</p>
<p><strong>A.</strong> Coefficient of Determination (R2)</p>
<p><strong>B.</strong> Relative Squared Error (RSE)</p>
<p><strong>C.</strong> Relative Absolute Error (RAE)</p>
<p><strong>D.</strong> Mean Absolute Error (MAE)</p>
<details class="- success">
<summary>Answer 97</summary>
<p><strong>Correct Answer:</strong> D</p>
</details>
<h2 id="question-98"><strong>Question 98</strong></h2>
<p>You are working as a cloud consultant for a major retail company. You are planning to create a bot from a frequently asked questions (FAQ) document. You found out that Microsoft Azure AI has many services that can help in creating a bot seamlessly.</p>
<p>Which azure AI service should you use?</p>
<p><strong>A.</strong> QnA Maker</p>
<p><strong>B.</strong> Language understanding</p>
<p><strong>C.</strong> Speech</p>
<p><strong>D.</strong> Text analysis</p>
<details class="- success">
<summary>Answer 98</summary>
<p><strong>Correct Answer:</strong> A</p>
</details>
<h2 id="question-99"><strong>Question 99</strong></h2>
<p>To complete the following sentence, select the appropriate option from the drop-down menu. <strong><em>_</em></strong><strong><em>_</em></strong>__ is a process in which the best machine learning algorithm to use for your specific data is selected for you.</p>
<p><strong>A.</strong> Automated machine learning (AutoML)</p>
<p><strong>B.</strong> Normalization</p>
<p><strong>C.</strong> Feature engineering</p>
<details class="- success">
<summary>Answer 99</summary>
<p><strong>Correct Answer:</strong> A</p>
<p>AutoML is a process in which the best machine learning algorithm to use for your specific data is selected for you.</p>
<p>AutoML tries different algorithms and tuning parameters in parallel while training a model and stops once it reaches predefined exit criteria. Generated output provides the list of used algorithms along with recommendations on the best ones to use.</p>
<p><strong>Incorrect Answers</strong></p>
<p>Normalization is a technique used to change the values in numeric columns to bring them up to the common scale; to the values ranging between 0 and 1, without loss of information or differences in the value ranges.</p>
<p>Feature engineering is a process of creating new features from within provided input dataset, which can help to better represent relationships and correlations between the input data and expected outcome.</p>
<p>Feature engineering improves the quality and performance of the trained model and increases its predictive power.</p>
</details>
<h2 id="question-100"><strong>Question 100</strong></h2>
<p>You build a QnA Maker bot by using a frequently asked questions (FAQ) page.</p>
<p>You need to add professional greetings and other responses to make the bot more user friendly.</p>
<p>What should you do?</p>
<p><strong>A.</strong> Increase the confidence threshold of responses</p>
<p><strong>B.</strong> Enable active learning</p>
<p><strong>C.</strong> Create multi-turn questions</p>
<p><strong>D.</strong> Add chit-chat</p>
<details class="- success">
<summary>Answer 100</summary>
<p><strong>Correct Answer:</strong> D</p>
<p><strong>Reference</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/chit-chat-knowledge-base?tabs=v1">https://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/chit-chat-knowledge-base?tabs=v1</a></p>
</details>
<h2 id="question-101"><strong>Question 101</strong></h2>
<p>Which two of these sources can you translate from one language into another? Each correct answer presents a complete solution. </p>
<p>Choose the correct answers</p>
<p><strong>A.</strong> Text</p>
<p><strong>B.</strong> Speech</p>
<p><strong>C.</strong> Image</p>
<p><strong>D.</strong> Video</p>
<p><strong>E.</strong> Handwriting</p>
<details class="- success">
<summary>Answer 101</summary>
<p><strong>Correct Answer:</strong> A and B</p>
<p>Text translation translates the text documents from one language into another language.</p>
<p>Speech translation translates spoken audio from one language into another language.</p>
<p>Converting handwriting to text is an example of Optical character recognition (OCR). OCR extracts handwritten text from an image. You can use text translation with the output from OCR.</p>
<p>Extracting the text in an image is also an example of Optical character recognition (OCR). OCR can recognize individual shapes as letters, numerals, punctuation, and other elements of text. OCR extracts the recognizable text from an image. You can use text translation with the output from OCR.</p>
<p>Videos can be analyzed and the spoken audio transcribed into text with media services. You can use text translation with the output from media services.</p>
</details>
<h2 id="question-102"><strong>Question 102</strong></h2>
<p><strong>Drag and Drop Question</strong></p>
<p>Match the computer vision type to the scenario. To answer, drag the appropriate type to each scenario. A type may be used once, more than once, or not at all.</p>
<p><img alt="102q" src="../ai-900-images/102q.png" /></p>
<details class="- success">
<summary>Answer 102</summary>
<p><img alt="102q" src="../ai-900-images/102a.png" /></p>
<p><strong>Face detection</strong> can be used to monitor a driver's face. The angle of the head can be determined and used to tell if the driver is looking at the road ahead, or looking down at a mobile device, or if the driver is showing signs of tiredness. Image classification can be used to evaluate scanned images from MRI machines to classify the images against trained images of known medical conditions.</p>
<p><strong>Object detection</strong> can be used to detect objects in an image. You can train Computer Vision to detect face masks. Face detection does not include the ability to recognize that a face is covered with a mask. Masks may actually prevent faces from being recognized.</p>
<p><strong>Optical character</strong> recognition (OCR) extracts text from an image. OCR can recognize individual shapes as letters, numerals, punctuation, and other elements of text.</p>
</details>
<h2 id="question-103"><strong>Question 103</strong></h2>
<p><strong>Hotspot Question</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><img alt="103q" src="../ai-900-images/103q.png" /></p>
<details class="- success">
<summary>Answer 103</summary>
<p><img alt="103a" src="../ai-900-images/103a.png" /></p>
<p><strong>Box 1:</strong> Yes</p>
<p>A bot created with the Azure Bot Framework SDK can be integrated with LUIS. You can add LUIS to your bot when you create the bot, or add LUIS later. You use the Dispatch tool to route messages from the bot to LUIS.</p>
<p>A bot created with the Azure Bot Framework SDK can be integrated with QnA Maker knowledge bases. You use the</p>
<p><strong>Box 2:</strong> Yes</p>
<p>Dispatch tool to route messages from the bot to QnA Maker. Your bot can choose which has the best response for the user.</p>
<p><strong>Box 3:</strong> Yes</p>
<p>A bot created with the Azure Bot Framework SDK can be integrated with bots created using Power Virtual Agents. You use the Dispatch tool to configure your bot to work with a Power Virtual Agent bot.</p>
</details>
<h2 id="question-104"><strong>Question 104</strong></h2>
<p>You have a webchat bot that provides responses from a QnA Maker knowledge base.</p>
<p>You need to ensure that the bot uses user feedback to improve the relevance of the responses over time.</p>
<p>What should you use?</p>
<p><strong>A.</strong> key phrase extraction</p>
<p><strong>B.</strong> sentiment analysis</p>
<p><strong>C.</strong> business logic</p>
<p><strong>D.</strong> active learning</p>
<details class="- success">
<summary>Answer 104</summary>
<p><strong>Correct Answer:</strong> D</p>
<p><strong>Reference</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/improve-knowledge-base">https://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/how-to/improve-knowledge-base</a></p>
</details>
<h2 id="question-105"><strong>Question 105</strong></h2>
<p>You are developing a conversational AI solution that will communicate with users through multiple channels including email, Microsoft Teams, and webchat.</p>
<p>Which service should you use?</p>
<p><strong>A.</strong> Text Analytics</p>
<p><strong>B.</strong> Azure Bot Service</p>
<p><strong>C.</strong> Translator</p>
<p><strong>D.</strong> Form Recognizer</p>
<details class="- success">
<summary>Answer 105</summary>
<p><strong>Correct Answer:</strong> B</p>
<p><strong>Reference</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-bot-service-4.0">https://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-bot-service-4.0</a></p>
</details>
<h2 id="question-106"><strong>Question 106</strong></h2>
<p>In which scenario should you use key phrase extraction?</p>
<p><strong>A.</strong> translating a set of documents from English to German</p>
<p><strong>B.</strong> generating captions for a video based on the audio track</p>
<p><strong>C.</strong> identifying whether reviews of a restaurant are positive or negative</p>
<p><strong>D.</strong> identifying which documents provide information about the same topics</p>
<details class="- success">
<summary>Answer 106</summary>
<p><strong>Correct Answer:</strong> C</p>
</details>
<h2 id="question-107"><strong>Question 107</strong></h2>
<p>You have insurance claim reports that are stored as text.</p>
<p>You need to extract key terms from the reports to generate summaries.</p>
<p>Which type of Al workload should you use?</p>
<p><strong>A.</strong> conversational Al</p>
<p><strong>B.</strong> anomaly detection</p>
<p><strong>C.</strong> natural language processing</p>
<p><strong>D.</strong> computer vision</p>
<details class="- success">
<summary>Answer 107</summary>
<p><strong>Correct Answer:</strong> C</p>
<p>Key phrase extraction is the concept of evaluating the text of a document, or documents, and then identifying the main talking points of the document(s). Key phase extraction is a part of Text Analytics. The Text Analytics service is a part of the Azure Cognitive Services offerings that can perform advanced natural language processing over raw text.</p>
<p><strong>Reference</strong></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/analyze-text-with-text-analytics-service/2-get-started-azure">https://docs.microsoft.com/en-us/learn/modules/analyze-text-with-text-analytics-service/2-get-started-azure</a></p>
</details>
<h2 id="question-108"><strong>Question 108</strong></h2>
<p>You need to track multiple versions of a model that was trained by using Azure Machine Learning.</p>
<p>What should you do?</p>
<p><strong>A.</strong> Provision an inference duster.</p>
<p><strong>B.</strong> Explain the model.</p>
<p><strong>C.</strong> Register the model.</p>
<p><strong>D.</strong> Register the training data.</p>
<details class="- success">
<summary>Answer 108</summary>
<p><strong>Correct Answer:</strong> C</p>
</details>
<h2 id="question-109"><strong>Question 109</strong></h2>
<p>To complete the sentence, select the appropriate option in the answer area. </p>
<p>Computer vision capabilities can be Deployed to<strong><em>_</em></strong>____</p>
<details class="- success">
<summary>Answer 109</summary>
<p><strong>Correct Answer:</strong> Integrate a facial recognition feature into an app.</p>
</details>
<h2 id="question-110"><strong>Question 110</strong></h2>
<p>You need to develop a chatbot for a website. The chatbot must answer users questions based on the information m the following documents:</p>
<ul>
<li>A product troubleshooting guide m a Microsoft Word document</li>
<li>A frequently asked questions (FAQ) list on a webpage</li>
</ul>
<p>Which service should you use to process the documents?</p>
<p><strong>A.</strong> Language Undemanding</p>
<p><strong>B.</strong> Text Analytics</p>
<p><strong>C.</strong> Azure Bot Service</p>
<p><strong>D.</strong> QnA Maker</p>
<details class="- success">
<summary>Answer 110</summary>
<p><strong>Correct Answer:</strong> D</p>
</details>
<h2 id="question-111"><strong>Question 111</strong></h2>
<p>You are authoring a Language Understanding (LUIS) application to support a music festival.</p>
<p>You want users to be able to ask questions about scheduled shows, such as: “Which act is playing on the main stage?”</p>
<p>The question “Which act is playing on the main stage?” is an example of which type of element?</p>
<p><strong>A.</strong> an intent</p>
<p><strong>B.</strong> an utterance</p>
<p><strong>C.</strong> a domain</p>
<p><strong>D.</strong> an entity</p>
<details class="- success">
<summary>Answer 111</summary>
<p><strong>Correct Answer:</strong> B</p>
<p>Utterances are input from the user that your app needs to interpret.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/LUIS/luis-concept-utterance">https://docs.microsoft.com/en-us/azure/cognitive-services/LUIS/luis-concept-utterance</a></p>
</details>
<h2 id="question-112"><strong>Question 112</strong></h2>
<p>You are building a knowledge base by using QnA Maker.</p>
<p>Which file format can you use to populate the knowledge base?</p>
<p><strong>A.</strong> PDF</p>
<p><strong>B.</strong> PPTX</p>
<p><strong>C.</strong> XML</p>
<p><strong>D.</strong> ZIP</p>
<details class="- success">
<summary>Answer 112</summary>
<p><strong>Correct Answer:</strong> D</p>
<p>Content types of documents you can add to a knowledge base:</p>
<p>Content types include many standard structured documents such as PDF, DOC, and TXT.</p>
<p><strong>Note:</strong> The tool supports the following file formats for ingestion:</p>
<p><strong>.tsv:</strong> QnA contained in the format Question(tab)Answer.</p>
<p><strong>.txt, .docx, .pdf:</strong> QnA contained as regular FAQ content--that is, a sequence of questions and answers.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/concepts/data-sources-and-content">https://docs.microsoft.com/en-us/azure/cognitive-services/qnamaker/concepts/data-sources-and-content</a></p>
</details>
<h2 id="question-113"><strong>Question 113</strong></h2>
<p>You use Azure Machine Learning designer to build a model pipeline. What should you create before you can run the pipeline?</p>
<p><strong>A.</strong> a Jupyter notebook</p>
<p><strong>B.</strong> a registered model</p>
<p><strong>C.</strong> a compute resource</p>
<details class="- success">
<summary>Answer 113</summary>
<p><strong>Correct Answer:</strong> C</p>
</details>
<h2 id="question-114"><strong>Question 114</strong></h2>
<p>You need to build an image tagging solution for social media that tags images of your friends automatically.</p>
<p>Which Azure Cognitive Services service should you use?</p>
<p><strong>A.</strong> Computer Vision</p>
<p><strong>B.</strong> Face</p>
<p><strong>C.</strong> Text Analytics</p>
<p><strong>D.</strong> Form Recognizer</p>
<details class="- success">
<summary>Answer 114</summary>
<p><strong>Correct Answer:</strong> B</p>
</details>
<h2 id="question-115"><strong>Question 115</strong></h2>
<p>You use drones to identify where weeds grow between rows of crops to send an Instruction for the removal of the weeds.</p>
<p>This is an example of which type of computer vision?</p>
<p><strong>A.</strong> scene segmentation</p>
<p><strong>B.</strong> optical character recognition (OCR)</p>
<p><strong>C.</strong> object detection</p>
<details class="- success">
<summary>Answer 115</summary>
<p><strong>Correct Answer:</strong> A</p>
</details>
<h2 id="question-116"><strong>Question 116</strong></h2>
<p><strong>Hotspot Question</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><img alt="116q" src="../ai-900-images/116q.png" /></p>
<details class="- success">
<summary>Answer 116</summary>
<p><img alt="116a" src="../ai-900-images/116a.png" /></p>
<p><strong>Reference</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-bot-service-4.0">https://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-bot-service-4.0</a></p>
</details>
<h2 id="question-117"><strong>Question 117</strong></h2>
<p>To complete the sentence, select the appropriate option in the answer area.</p>
<p>Using Recency, Frequency, and Monetary (RFM) values to identify segments of a customer base is an example of<strong><em>_</em></strong>____</p>
<details class="- success">
<summary>Answer 117</summary>
<p><strong>Correct Answer:</strong> classification</p>
</details>
<h2 id="question-118"><strong>Question 118</strong></h2>
<p><strong>Hotspot Question</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><img alt="118q" src="../ai-900-images/118q.png" /></p>
<details class="- success">
<summary>Answer 118</summary>
<p><img alt="118a" src="../ai-900-images/118a.png" /></p>
<p><strong>Reference</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-bot-service-4.0">https://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-bot-service-4.0</a></p>
</details>
<h2 id="question-119"><strong>Question 119</strong></h2>
<p><strong>Hotspot Question</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><img alt="119q" src="../ai-900-images/119q.png" /></p>
<details class="- success">
<summary>Answer 119</summary>
<p><img alt="119a" src="../ai-900-images/119a.png" /></p>
</details>
<h2 id="question-120"><strong>Question 120</strong></h2>
<p><strong>Hotspot Question</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><img alt="120q" src="../ai-900-images/120q.png" /></p>
<details class="- success">
<summary>Answer 120</summary>
<p><img alt="120a" src="../ai-900-images/120a.png" /></p>
<p>The translator service provides multi-language support for text translation, transliteration, language detection, and dictionaries.</p>
<p>Speech-to-Text, also known as automatic speech recognition (ASR), is a feature of Speech Services that provides transcription.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/Translator/translator-info-overview">https://docs.microsoft.com/en-us/azure/cognitive-services/Translator/translator-info-overview</a></p>
<p><a href="https://docs.microsoft.com/en-us/legal/cognitive-services/speech-service/speech-to-text/transparency-note">https://docs.microsoft.com/en-us/legal/cognitive-services/speech-service/speech-to-text/transparency-note</a></p>
</details>
<h2 id="question-121"><strong>Question 121</strong></h2>
<p><strong>Hotspot Question</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><img alt="121q" src="../ai-900-images/121q.png" /></p>
<details class="- success">
<summary>Answer 121</summary>
<p><img alt="121a" src="../ai-900-images/121a.png" /></p>
</details>
<h2 id="question-122"><strong>Question 122</strong></h2>
<p><strong>Hotspot Question</strong></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><img alt="122q" src="../ai-900-images/122q.png" /></p>
<details class="- success">
<summary>Answer 122</summary>
<p><img alt="122a" src="../ai-900-images/122a.png" /></p>
</details>
<h2 id="question-123"><strong>Question 123</strong></h2>
<p><strong>Drag and Drop Question</strong></p>
<p>Match the services to the appropriate descriptions.</p>
<p>To answer, drag the appropriate service from the column on the left to its description on the right. Each service may be used once, more than once, or not at all.</p>
<p><strong>NOTE:</strong> Each correct match is worth one point</p>
<p><img alt="123q" src="../ai-900-images/123q.png" /></p>
<details class="- success">
<summary>Answer 123</summary>
<p><img alt="123a" src="../ai-900-images/123a.png" /></p>
</details>
<h2 id="question-124"><strong>Question 124</strong></h2>
<p><strong>Drag and Drop Question</strong></p>
<p>Match the principles of responsible AI to the appropriate descriptions. To answer, drag the appropriate principle from the column on the left to its description on the right. Each principle may be used once, more than once, or not at all.</p>
<p><strong>NOTE:</strong> Each correct match is worth one point.</p>
<p><img alt="124q" src="../ai-900-images/124q.png" /></p>
<details class="- success">
<summary>Answer 124</summary>
<p><img alt="124a" src="../ai-900-images/124a.png" /></p>
</details>
<h2 id="question-125"><strong>Question 125</strong></h2>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><img alt="125q" src="../ai-900-images/125q.png" /></p>
<details class="- success">
<summary>Answer 125</summary>
<p><img alt="125a" src="../ai-900-images/125a.png" /></p>
</details>
<h2 id="question-126"><strong>Question 126</strong></h2>
<p>You plan to develop a bot that will enable users to query a knowledge base by using natural language processing.</p>
<p>Which two services should you include in the solution? Each correct answer presents part of the solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> QnA Maker</p>
<p><strong>B.</strong> Azure Bot Service</p>
<p><strong>C.</strong> Form Recognizer</p>
<p><strong>D.</strong> Anomaly Detector</p>
<details class="- success">
<summary>Answer 126</summary>
<p><strong>Correct Answer:</strong> A and B</p>
<p><strong>Reference</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-bot-service-4.0">https://docs.microsoft.com/en-us/azure/bot-service/bot-service-overview-introduction?view=azure-bot-service-4.0</a></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/luis/choose-natural-language-processing-service">https://docs.microsoft.com/en-us/azure/cognitive-services/luis/choose-natural-language-processing-service</a></p>
</details>
<h2 id="question-127"><strong>Question 127</strong></h2>
<p>In which two scenarios can you use a speech synthesis solution? Each correct answer presents a complete solution.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><strong>A.</strong> an automated voice that reads back a credit card number entered into a telephone by using a numeric keypad</p>
<p><strong>B.</strong> generating live captions for a news broadcast</p>
<p><strong>C.</strong> extracting key phrases from the audio recording of a meeting</p>
<p><strong>D.</strong> an AI character in a computer game that speaks audibly to a player</p>
<details class="- success">
<summary>Answer 127</summary>
<p><strong>Correct Answer:</strong> A and D</p>
<p>Azure Text to Speech is a Speech service feature that converts text to lifelike speech.</p>
<p><strong>Incorrect Answers:</strong></p>
<p><strong>C:</strong> Extracting key phrases is not speech synthesis.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://azure.microsoft.com/en-in/services/cognitive-services/text-to-speech/">https://azure.microsoft.com/en-in/services/cognitive-services/text-to-speech/</a></p>
</details>
<h2 id="question-128"><strong>Question 128</strong></h2>
<p><strong>Drag and Drop Question</strong></p>
<p>You need to scan the news for articles about your customers and alert employees when there is a negative article.</p>
<p>Positive articles must be added to a press book.</p>
<p>Which natural language processing tasks should you use to complete the process? To answer, drag the appropriate tasks to the correct locations. Each task may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.</p>
<p><strong>NOTE:</strong> Each correct selection is worth one point.</p>
<p><img alt="128q" src="../ai-900-images/128q.png" /></p>
<details class="- success">
<summary>Answer 128</summary>
<p><img alt="128a" src="../ai-900-images/128a.png" /></p>
<p><strong>Box 1:</strong> Entity recognition</p>
<p>The Named Entity Recognition module in Machine Learning Studio (classic), to identify the names of things, such as people, companies, or locations in a column of text.</p>
<p>Named entity recognition is an important area of research in machine learning and natural language processing (NLP), because it can be used to answer many real-world questions, such as:</p>
<p>Which companies were mentioned in a news article?</p>
<p>Does a tweet contain the name of a person? Does the tweet also provide his current location?</p>
<p>Were specified products mentioned in complaints or reviews?</p>
<p><strong>Box 2:</strong> Sentiment Analysis</p>
<p>The Text Analytics API's Sentiment Analysis feature provides two ways for detecting positive and negative sentiment. If you send a Sentiment Analysis request, the API will return sentiment labels (such as "negative", "neutral" and"positive") and confidence scores at the sentence and document-level.</p>
<p><strong>Reference:</strong></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/named-entity-recognition">https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/named-entity-recognition</a></p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/how-tos/text-analytics-how-to-sentiment-analysis">https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/how-tos/text-analytics-how-to-sentiment-analysis</a></p>
</details>
<h2 id="question-129"><strong>Question 129</strong></h2>
<p><strong>Domain:</strong> Describe AI workloads and considerations</p>
<p>Please select all options that are NOT the key elements of Artificial Intelligence. (<strong><em>2 answers</em></strong>)</p>
<p><strong>A.</strong> Machine Learning</p>
<p><strong>B.</strong> Anomaly Detection</p>
<p><strong>C.</strong> Computer Vision</p>
<p><strong>D.</strong> Object Detection</p>
<p><strong>E.</strong> Natural Language Processing</p>
<p><strong>F.</strong> Conversational AI</p>
<p><strong>G.</strong> Automated Machine Learning</p>
<details class="- success">
<summary>Answer 129</summary>
<p><strong>Correct Answers:</strong> D and G</p>
<p>There are five key elements of Microsoft Artificial Intelligence:</p>
<ul>
<li><strong>Machine Learning</strong> - the foundation of AI systems.</li>
<li><strong>Anomaly Detection</strong> - tools and services for identification of the unusual activities.</li>
<li><strong>Computer Vision</strong> - tools and services for understanding and recognising objects in images, video, faces and text.</li>
<li><strong>Natural Language</strong> Processing - tools and services for language understanding: text, speech, text analysis and translation Conversational AI - tools and services for intelligent conversation.</li>
</ul>
<p><strong>Option D is correct.</strong> Object Detection - is one of the common tasks of Computer Vision and is not the key element of Artificial Intelligence.</p>
<p><strong>Options G is correct.</strong> Automated Machine Learning - is a feature of Machine Learning and is not the key element of Artificial Intelligence.</p>
<p>All other options are incorrect because they are the key elements of Artificial Intelligence.</p>
<p>For more information about the key elements of AI, please visit the below URL:</p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/1-introduction">https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/1-introduction</a></p>
</details>
<h2 id="question-130"><strong>Question 130</strong></h2>
<p><strong>Domain:</strong> Describe AI workloads and considerations</p>
<p>You created an AI solution. Along with solution deployment, you provided information about the solution's possibilities and limitations. By providing this information, with what principle for responsible AI did you comply?</p>
<p><strong>A.</strong> Fairness</p>
<p><strong>B.</strong> Reliability and safety</p>
<p><strong>C.</strong> Privacy and security</p>
<p><strong>D.</strong> Transparency</p>
<p><strong>E.</strong> Inclusiveness</p>
<p><strong>F.</strong> Accountability</p>
<details class="- success">
<summary>Answer 130</summary>
<p><strong>Correct Answers:</strong> D</p>
<p>Microsoft recognizes six principles of responsible AI:</p>
<p>Fairness, Reliability and safety, Privacy and security, Transparency, Inclusiveness Accountability.</p>
<p>The principle of Transparency helps people to understand how to use AI solutions, their behavior, possibilities, and limitations.  </p>
<p>All other options are incorrect.</p>
<p>For more information about guiding principles for responsible AI, please visit the below URLs:</p>
<p><a href="https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6">https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6</a></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles">https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/4-guiding-principles</a></p>
</details>
<h2 id="question-131"><strong>Question 131</strong></h2>
<p><strong>Domain:</strong> Describe fundamental principles of machine learning on Azure</p>
<p>You are working for a car dealership. Your boss asks you to provide him information about how many blue cars he needs to order for the next quarter.</p>
<p>You decide to create an ML model and choose an unsupervised machine learning approach.</p>
<p>Will this help you to achieve your goal?</p>
<p><strong>A.</strong> Yes</p>
<p><strong>B.</strong> No</p>
<details class="- success">
<summary>Answer 131</summary>
<p><strong>Correct Answers:</strong> B</p>
<p>Your task is to provide a numeric prediction. You can achieve this by creating a regression model based on the historical sales data of the blue cars from previous quarters. A Regression and Classification modeling types are two parts of Supervised machine learning. Only Clustering belongs to Unsupervised machine learning. If you choose the Unsupervised machine learning approach, you will not achieve your goal.</p>
<p>For more information about Supervised and Unsupervised ML, please visit the below URL:</p>
<p><a href="https://azure.microsoft.com/en-us/overview/what-is-machine-learning-platform/#benefits">https://azure.microsoft.com/en-us/overview/what-is-machine-learning-platform/#benefits</a></p>
</details>
<h2 id="question-132"><strong>Question 132</strong></h2>
<p><strong>Domain:</strong> Describe fundamental principles of machine learning on Azure</p>
<p>You are working for a car dealership. Your boss asks you to provide him forecast information: will the new car model be successful or not. The new model has a variety of engine improvements, more comfortable seats, and a sunroof. You compiled the list of data about previous successful models with their characteristics and sales numbers.</p>
<p>What should you do in the pre-processing data stage that would help you to predict the success of the new model?</p>
<p><strong>A.</strong> Data selection</p>
<p><strong>B.</strong> Training set selection</p>
<p><strong>C.</strong> Data for model evaluation selection</p>
<p><strong>D.</strong> Feature selection</p>
<p><strong>E.</strong> Data classification</p>
<details class="- success">
<summary>Answer 132</summary>
<p><strong>Correct Answers:</strong> D</p>
<p>During pre-processing, you need to work with data to select features that influence the label prediction. In this problem, features are the engine characteristics (power or volume), seat comforts, etc. They could help the ML model to predict the success of the new car model. Maybe the sunroof is not essential for predicting the label, and we need to discard this feature from the final set of features that we will use for model training.</p>
<p>In short, Feature selection helps us to narrow down the features that are important for our label prediction and discard all features that don’t play or play a minimal role in a label prediction. As a result, our trained model and prediction will be more efficient.</p>
<p>All other options are incorrect because they are parts of the different data processing events that are irrelevant to the pre-processing (Training set selection or Data for model evaluation selection) or too generic (Data selection or Data Classification).</p>
<p>For more information about Feature selection, please visit the below URL:</p>
<p>[https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/select-features]</p>
</details>
<h2 id="question-133"><strong>Question 133</strong></h2>
<p><strong>Domain:</strong> Describe fundamental principles of machine learning on Azure</p>
<p>You created a classification model with four possible classes.</p>
<p>What will be the size of the confusion matrix? </p>
<p><strong>A.</strong> 2x2</p>
<p><strong>B.</strong> 3x3</p>
<p><strong>C.</strong> 4x4</p>
<p><strong>D.</strong> 6x6</p>
<p><strong>E.</strong> 10x10</p>
<details class="- success">
<summary>Answer 133</summary>
<p><strong>Correct Answers:</strong> C</p>
<p>The confusion matrix provides a tabulated view of predicted and actual values for each class. If we are predicting the classification for four classes, our confusion matrix will have 4x4 size.</p>
<p>All other options are incorrect.</p>
<p>For more information about the Confusion matrix, please visit the below URL:</p>
<p>https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml#confusion-matrix</p>
</details>
<h2 id="question-134"><strong>Question 134</strong></h2>
<p><strong>Domain:</strong> Describe fundamental principles of machine learning on Azure</p>
<p>When you are preparing data for the model training, you have to use your domain knowledge to select the label (or labels), features, and scale and normalize them.</p>
<p>What is the generic name for the process that includes all the steps mentioned above?</p>
<p><strong>A.</strong> Feature selections</p>
<p><strong>B.</strong> Data normalization</p>
<p><strong>C.</strong> Model training</p>
<p><strong>D.</strong> Featurization</p>
<p><strong>E.</strong> Missing data handling</p>
<details class="- success">
<summary>Answer 134</summary>
<p><strong>Correct Answers:</strong> D</p>
<p>Data pre-processing that involves various techniques, like scaling, normalization or feature engineering, etc. calls featurization.</p>
<p><strong>Option A is incorrect</strong> because Feature selections is one of the elements of featurization.</p>
<p><strong>Option B is incorrect</strong> because Data normalization is also one of the elements of featurization.</p>
<p><strong>Option C is incorrect</strong> because Model Training is the next predictive modeling step after featurization.</p>
<p><strong>Option E is incorrect</strong> because Missing data handling is one of the elements of featurization.</p>
<p>For more information about Featurization, please visit the below URLs:</p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml#feature-engineering">https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml#feature-engineering</a></p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features#featurization">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features#featurization</a></p>
</details>
<h2 id="question-135"><strong>Question 135</strong></h2>
<p><strong>Domain:</strong> Describe fundamental principles of machine learning on Azure</p>
<p>What are the four types of Compute resources you can use in Azure Machine Learning Studio?</p>
<p>Please select all that apply. (<strong><em>4 answers</em></strong>)</p>
<p><strong>A.</strong> Compute Instances</p>
<p><strong>B.</strong> Automated ML instances</p>
<p><strong>C.</strong> Compute clusters</p>
<p><strong>D.</strong> Inference clusters</p>
<p><strong>E.</strong> Classification clusters</p>
<p><strong>F.</strong> Attached compute</p>
<p><strong>G.</strong> AKS Cluster instances</p>
<details class="- success">
<summary>Answer 135</summary>
<p><strong>Correct Answers:</strong> A, C, D, and F</p>
<p>When you open Compute blade in Microsoft Azure Machine Learning Studio, you can see all four compute resources:</p>
<p><img alt="135a" src="../ai-900-images/135a.png" /></p>
<p><strong>Option B is incorrect</strong> because Automated ML instances is the generic ML instance.</p>
<p><strong>Option G is incorrect</strong> because AKS Cluster Instance is the generic representation of Azure Kubernetes cluster.</p>
<p>For more information about Azure ML Studio compute resources, please visit the below URLs:</p>
<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-studio#portal-create">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-studio#portal-create</a></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/use-automated-machine-learning/create-compute">https://docs.microsoft.com/en-us/learn/modules/use-automated-machine-learning/create-compute</a></p>
</details>
<h2 id="question-136"><strong>Question 136</strong></h2>
<p><strong>Domain:</strong> Describe features of computer vision workloads on Azure</p>
<p>You created a Custom Vision model. You want your model to detect trained objects on the photos.</p>
<p>What information will you get about each object if you are using an object detection model?</p>
<p>Please select all that apply. (<strong><em>3 answers</em></strong>)</p>
<p><strong>A.</strong> Image type</p>
<p><strong>B.</strong> Bounding box</p>
<p><strong>C.</strong> Image category</p>
<p><strong>D.</strong> Class name</p>
<p><strong>E.</strong> Probability score</p>
<p><strong>F.</strong> Content name</p>
<details class="- success">
<summary>Answer 136</summary>
<p><strong>Correct Answers:</strong> B, D, and E.</p>
<p>Object detection is the form of ML that helps to recognize objects on the images. Each recognizable object will be put in the bounding box with the class name and probability score.</p>
<p>Here is the Microsoft information about the object detection model:</p>
<p><img alt="136a" src="../ai-900-images/136a.png" /></p>
<p>All other options are incorrect because they are not part of the return information from the object detection model.</p>
<p>For more information about Object detection, please visit the below URL:</p>
</details>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/detect-objects-images-custom-vision/1-introduction">https://docs.microsoft.com/en-us/learn/modules/detect-objects-images-custom-vision/1-introduction</a></p>
<h2 id="question-137"><strong>Question 137</strong></h2>
<p><strong>Domain:</strong> Describe features of computer vision workloads on Azure</p>
<p>The application scans a document with a lot of pages. It returns the following information for each page: page information, lines information, and words for each line with a confidence level. </p>
<p>What API does the application use to scan the document?</p>
<p><strong>A.</strong> OCR</p>
<p><strong>B.</strong> NLP</p>
<p><strong>C.</strong> Read</p>
<p><strong>D.</strong> Text Analytics</p>
<p><strong>E.</strong> LUIS</p>
<details class="- success">
<summary>Answer 137</summary>
<p><strong>Correct Answers:</strong> C</p>
<p>Read API is part of Computer Vision services. It helps to "read" texts within predominantly document images. Read API is an asynchronous service specially designed for the heavy on text images or documents with a lot of the distortions. It produces a result that includes: page information for each page including page size and orientation; information about each line on the page and information about each word in each line including bounding box of each word as indication of the word position in the image.</p>
<p><strong>Option A is incorrect</strong> since OCR API is a synchronous service for the recognition of small amounts of text in the images. It returns regions of the text in the image, lines of the text in the region, and words in each line.</p>
<p><strong>Option B is incorrect</strong> since Natural Language Processing (NLP) is one the key elements of Artificial Intelligence and is not the part of Computer Vision that deals with text extraction from the images.</p>
<p><strong>Option D is incorrect</strong> since Text Analytics is the part of Natural Processing Language (NLP) and is not the part of Computer Vision that deals with text extraction from the images.</p>
<p><strong>Option E is incorrect</strong> since Language Understanding Intelligent Service (LUIS) is the part of Natural Processing Language (NLP) and is not the part of Computer Vision that deals with text extraction from the images.</p>
<p>For more information about Read API, please visit the below URLs:</p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-recognizing-text">https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-recognizing-text</a></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/read-text-computer-vision/2-ocr-azure">https://docs.microsoft.com/en-us/learn/modules/read-text-computer-vision/2-ocr-azure</a></p>
</details>
<h2 id="question-138"><strong>Question 138</strong></h2>
<p><strong>Domain:</strong> Describe features of computer vision workloads on Azure</p>
<p>You created a Custom Vision model using the Custom Vision portal.</p>
<p>What information do you need to provide to the developers to use this model?</p>
<p>Please select all that apply. (<strong><em>4 answers</em></strong>)</p>
<p><strong>A.</strong> Project ID</p>
<p><strong>B.</strong> Security Key</p>
<p><strong>C.</strong> Model name</p>
<p><strong>D.</strong> Prediction key</p>
<p><strong>E.</strong> Cognitive Service key</p>
<p><strong>F.</strong> Prediction Endpoint</p>
<details class="- success">
<summary>Answer 138</summary>
<p><strong>Correct Answers:</strong> A, C, D, and F.</p>
<p>If you create a Cognitive Service to train and publish the Custom Vision model, you can provide a Cognitive Service endpoint and Cognitive Service key to the developers for access to the model. But if you use the Custom Vision portal or create a Custom Vision resource within Cognitive Service, you will have two separate resources for training and publishing a model. In this case, you need to provide the four pieces of information to the developers: Project ID, Model name, Prediction Key, and Prediction Endpoint.</p>
<p><strong>Option B is incorrect</strong> since Security Key is just a generic key that isn't applicable in this case.</p>
<p><strong>Option E is incorrect</strong> since we need to provide the pair: Cognitive Service endpoint and Cognitive Service key. Only one of them, a Cognitive Service key, will not work. </p>
<p>For more information about Custom Vision, please visit the below URLs:</p>
<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/home">https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/home</a></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/classify-images-custom-vision/2-azure-image-classification">https://docs.microsoft.com/en-us/learn/modules/classify-images-custom-vision/2-azure-image-classification</a></p>
</details>
<h2 id="question-139"><strong>Question 139</strong></h2>
<p><strong>Domain:</strong> Describe features of Natural Language Processing (NLP) workloads on Azure</p>
<p>You are working at the hotel chain. You are planning to apply Natural Language Processing for the sentiment analysis of the customer reviews.</p>
<p>What sentiment score should you expect for the following review: "The prices were ridiculously high. We could stay at the palace for that price! The water in the shower was cold, no hot water whatsoever"? </p>
<p><strong>A.</strong> 1</p>
<p><strong>B.</strong> 0.5</p>
<p><strong>C.</strong> 2</p>
<p><strong>D.</strong> 0.9</p>
<p><strong>E.</strong> 0.1</p>
<details class="- success">
<summary>Answer 139</summary>
<p><strong>Correct Answers:</strong> E.</p>
<p>Sentiment analysis is producing the sentiment score between 0 and 1. A score close to 0 means a negative sentiment, and close to 1 - positive.  And in cases with neutral or undefined sentiment the score is 0.5. In this problem, the review is negative, and we should expect a score of 0.1.</p>
<p>All other options are incorrect.</p>
<p>For more information about Sentiment Analysis, please visit the below URL:</p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/analyze-text-with-text-analytics-service/2-get-started-azure">https://docs.microsoft.com/en-us/learn/modules/analyze-text-with-text-analytics-service/2-get-started-azure</a></p>
</details>
<h2 id="question-140"><strong>Question 140</strong></h2>
<p><strong>Domain:</strong> Describe features of Natural Language Processing (NLP) workloads on Azure</p>
<p>What are the four types of entities that you can create during the authoring of the LUIS Application? (<strong><em>4 answers</em></strong>)</p>
<p><strong>A.</strong> Machine-Learned</p>
<p><strong>B.</strong> List</p>
<p><strong>C.</strong> FAQ document</p>
<p><strong>D.</strong> RegEx</p>
<p><strong>E.</strong> Chit-chat</p>
<p><strong>F.</strong> Pattern.any</p>
<p><strong>G.</strong> Alternative phrasing</p>
<details class="- success">
<summary>Answer 140</summary>
<p><strong>Correct Answers:</strong> A, B, D, and F</p>
<p>During an authoring phase for a Language Understanding application, we need to create intents, entities, and train a model. There are four types of entities that we can create: Machine-Learned, List, RegEx, and Pattern.any. </p>
<p>All other options are incorrect because they are parts for creating a Knowledge base for Q&amp;A Maker and Azure Bot Service.</p>
<p>For more information about LUIS, please visit the below URLs:</p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/create-language-model-with-language-understanding/2-get-started">https://docs.microsoft.com/en-us/learn/modules/create-language-model-with-language-understanding/2-get-started</a></p>
<p><a href="https://www.luis.ai/">https://www.luis.ai/</a> </p>
</details>
<h2 id="question-141"><strong>Question 141</strong></h2>
<p><strong>Domain:</strong> Describe features of conversational AI workloads on Azure</p>
<p>What components do you need to create a simple Web Chat Bot?</p>
<p>Select all that apply. (<strong><em>2 answers</em></strong>)</p>
<p><strong>A.</strong> Entities</p>
<p><strong>B.</strong> Knowledge base</p>
<p><strong>C.</strong> Utterances</p>
<p><strong>D.</strong> Bot Service</p>
<p><strong>E.</strong> LUIS</p>
<p><strong>F.</strong> Text Analytics</p>
<details class="- success">
<summary>Answer 141</summary>
<p><strong>Correct Answers:</strong> B and D</p>
<p>To create a simple Web Chat Bot, you need just two components: Knowledge Base and Bot Service.</p>
<p>We can create a Knowledge base from web site information or FAQ documents, etc. Usually, the Knowledge base is a list of question and answer pairs. Bot Service provides an interface to interact with a Knowledge Base from different channels.</p>
<p><strong>Option A and C are incorrect</strong> because Entities and Utterances are the parts of LUIS authoring and are not components of Web Chat Bot.</p>
<p><strong>Option E is incorrect</strong> since Language Understanding Intelligent Service (LUIS) is Natural Processing Language (NLP) service and is not a component of Web Chat Bot.</p>
<p><strong>Option F is incorrect</strong> since Text Analytics is  Natural Processing Language (NLP) service and is not a component of Web Chat Bot.</p>
<p>For more information about Bot Service, please visit the below URLs:</p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/build-faq-chatbot-qna-maker-azure-bot-service/1-introduction">https://docs.microsoft.com/en-us/learn/modules/build-faq-chatbot-qna-maker-azure-bot-service/1-introduction</a></p>
<p><a href="https://azure.microsoft.com/en-us/services/bot-service/">https://azure.microsoft.com/en-us/services/bot-service/</a></p>
</details>
<h2 id="question-142"><strong>Question 142</strong></h2>
<p><strong>Domain:</strong> Describe features of conversational AI workloads on Azure</p>
<p>You want to build a personal virtual assistant. What service will you use to connect your assistant with various input channels and devices?</p>
<p><strong>A.</strong> Computer Vision</p>
<p><strong>B.</strong> Azure Bot Service</p>
<p><strong>C.</strong> QnA Maker</p>
<p><strong>D.</strong> LUIS</p>
<p><strong>E.</strong> Speech to Text</p>
<p><strong>F.</strong> Text Analytics</p>
<details class="- success">
<summary>Answer 142</summary>
<p><strong>Correct Answers:</strong> B</p>
<p>Azure Bot Service connects various channels and devices that users can use for their inquiries.</p>
<p>The Microsoft documentation provides the following information about Virtual Assistant</p>
<p><img alt="142a" src="../ai-900-images/142a.png" /></p>
<p>As you can see on the left side, Azure Bot Service serves as data input for Virtual Assistant.</p>
<p>All other options are incorrect.</p>
<p>For more information about Personal Assistant, please visit the below URLs:</p>
<p><a href="https://docs.microsoft.com/en-us/azure/bot-service/bot-builder-virtual-assistant-introduction?view=azure-bot-service-4.0">https://docs.microsoft.com/en-us/azure/bot-service/bot-builder-virtual-assistant-introduction?view=azure-bot-service-4.0</a></p>
</details>
<h2 id="question-143"><strong>Question 143</strong></h2>
<p><strong>Domain:</strong> Describe features of conversational AI workloads on Azure</p>
<p>You build a Bot using Bot Framework and Azure Bot Service. You want to extend the capabilities of your Bot.</p>
<p>What will you use to achieve your goal? </p>
<p><strong>A.</strong> Custom Vision</p>
<p><strong>B.</strong> Language Translation</p>
<p><strong>C.</strong> Chit-Chat</p>
<p><strong>D.</strong> Skills</p>
<p><strong>E.</strong> Text to Speech</p>
<p><strong>F.</strong> FAQ Document</p>
<details class="- success">
<summary>Answer 143</summary>
<p><strong>Correct Answers:</strong> D</p>
<p>Using Bot Framework Skills, you can easily extend the capabilities of your Bot. Skills are like standalone bots that focus on a specific function, like Calendar, To Do, Point of Interest, etc.</p>
<p>In the Virtual Assistant design, Bot Framework dispatches actions to Skills.</p>
<p>Here is the Microsoft information about Bot Framework and Skills as parts of Virtual Assistant:</p>
<p><img alt="143a" src="../ai-900-images/143a.png" /></p>
<p><strong>Option A is incorrect</strong> because Custom Vision is one the Computer Vision services and potentially can extend Bot functionality as part of the Skill.</p>
<p><strong>Option B and E are incorrect</strong> because Language Translation and Text to Speech are Natural Language Processing services and potentially can extend Bot functionality as part of the Skill.</p>
<p><strong>Option C and F are incorrect</strong> because Chit-Chat and FAQ documents are the parts for creating a Knowledge base for Q&amp;A Maker and Azure Bot Service.</p>
<p>For more information about Bot Framework Skills, please visit the below URLs:</p>
<p><a href="https://microsoft.github.io/botframework-solutions/overview/skills/">https://microsoft.github.io/botframework-solutions/overview/skills/</a></p>
<p><a href="https://microsoft.github.io/botframework-solutions/overview/virtual-assistant-solution/">https://microsoft.github.io/botframework-solutions/overview/virtual-assistant-solution/</a></p>
</details>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2020 - 2022 Mark Schwarz
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": ["search.suggest", "search.highlight", "search.tabs.link", "content.tabs.link", "navigation.indexes", "navigation.tabs", "navigation.top"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../../assets/javascripts/workers/search.cefbb252.min.js"}</script>
    
    
      <script src="../../../assets/javascripts/bundle.a5f8ea78.min.js"></script>
      
    
  </body>
</html>